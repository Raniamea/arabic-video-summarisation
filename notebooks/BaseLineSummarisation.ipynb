{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKqfSuLLZVAv5OCiR0jijz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raniamea/arabic-video-summarisation/blob/main/notebooks/BaseLineSummarisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Mount Google Drive and define base path\n",
        "# =========================================================\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Safe mount: avoids duplicate mount warnings\n",
        "if not os.path.ismount(\"/content/drive\"):\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "# Define base path for project files\n",
        "BASE_PATH = \"/content/drive/MyDrive/ArabicVideoSummariser\"\n",
        "os.makedirs(BASE_PATH, exist_ok=True)\n",
        "print(f\"Base path set to: {BASE_PATH}\")\n"
      ],
      "metadata": {
        "id": "rky8UsfIo2-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"evaluate>=0.4.2,<0.5.0\" \"rouge-score==0.1.2\" \"bert-score==0.3.13\" \"transformers>=4.44,<4.47\""
      ],
      "metadata": {
        "id": "1JqcQRJ6rPtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# Baseline Evaluation of Pre-trained Summarization Models\n",
        "# with ROUGE and BERTScore (fixed version)\n",
        "# ==============================================================\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch, pandas as pd, evaluate, os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ---- Working public models ----\n",
        "models_to_test = {\n",
        "    \"AraBART\": \"moussaKam/AraBART\",                    # working AraBART\n",
        "    \"AraBART-finetuned\": \"ahmeddbahaa/AraBART-finetuned-ar\",\n",
        "    \"mT5-XLsum\": \"csebuetnlp/mT5_multilingual_XLSum\",\n",
        "    \"mBART-50\": \"facebook/mbart-large-50\"\n",
        "}\n",
        "\n",
        "# ---- Paths ----\n",
        "transcript_path = \"/content/drive/MyDrive/ArabicVideoSummariser/transcripts/KhanElkhalili_ar.txt\"\n",
        "reference_path  = \"/content/drive/MyDrive/ArabicVideoSummariser/summaries/KhanElkhalili_Summary.txt\"\n",
        "\n",
        "with open(transcript_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    transcript_text = f.read().strip()\n",
        "\n",
        "with open(reference_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    reference_summary = f.read().strip()\n",
        "\n",
        "transcript_text = transcript_text[:2000]\n",
        "\n",
        "# ---- Inference settings ----\n",
        "max_input_tokens = 512\n",
        "max_new_tokens = 150\n",
        "num_beams = 4\n",
        "\n",
        "def generate_summary(model_name, model_id, text):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_id).to(device)\n",
        "    model.eval()\n",
        "\n",
        "    if \"mbart\" in model_id.lower():\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_input_tokens).to(device)\n",
        "        forced_bos = tokenizer.lang_code_to_id.get(\"ar_AR\", None)\n",
        "        ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            num_beams=num_beams,\n",
        "            forced_bos_token_id=forced_bos\n",
        "        )\n",
        "    else:\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_input_tokens).to(device)\n",
        "        ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            num_beams=num_beams,\n",
        "            early_stopping=True\n",
        "        )\n",
        "    return tokenizer.decode(ids[0], skip_special_tokens=True)\n",
        "\n",
        "# ---- Evaluation metrics ----\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, mid in models_to_test.items():\n",
        "    print(f\"\\nRunning model: {name}\")\n",
        "    try:\n",
        "        summary = generate_summary(name, mid, transcript_text)\n",
        "\n",
        "        # Compute ROUGE\n",
        "        rouge_scores = rouge.compute(\n",
        "            predictions=[summary],\n",
        "            references=[reference_summary],\n",
        "            use_stemmer=True\n",
        "        )\n",
        "\n",
        "        # Compute BERTScore (Arabic) without baseline scaling\n",
        "        bert = bertscore.compute(\n",
        "            predictions=[summary],\n",
        "            references=[reference_summary],\n",
        "            lang=\"ar\"\n",
        "        )\n",
        "        bert_f1 = bert[\"f1\"][0]\n",
        "\n",
        "        results.append({\n",
        "            \"Model\": name,\n",
        "            \"ROUGE-1\": round(rouge_scores[\"rouge1\"] * 100, 2),\n",
        "            \"ROUGE-2\": round(rouge_scores[\"rouge2\"] * 100, 2),\n",
        "            \"ROUGE-L\": round(rouge_scores[\"rougeL\"] * 100, 2),\n",
        "            \"BERTScore F1\": round(bert_f1 * 100, 2),\n",
        "            \"Generated Summary\": summary[:400] + (\"...\" if len(summary) > 400 else \"\")\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error running {name}: {e}\")\n",
        "        results.append({\n",
        "            \"Model\": name,\n",
        "            \"ROUGE-1\": None,\n",
        "            \"ROUGE-2\": None,\n",
        "            \"ROUGE-L\": None,\n",
        "            \"BERTScore F1\": None,\n",
        "            \"Generated Summary\": f\"Error: {e}\"\n",
        "        })\n",
        "\n",
        "# ---- Results ----\n",
        "df = pd.DataFrame(results)\n",
        "display(df)\n",
        "\n",
        "# ---- Save to Drive for thesis logs ----\n",
        "save_path = \"/content/drive/MyDrive/ArabicVideoSummariser/eval_results.csv\"\n",
        "df.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
        "print(f\"\\n✅ Results saved to: {save_path}\")\n",
        "\n",
        "# ---- Print summaries ----\n",
        "for r in results:\n",
        "    print(f\"\\n{'='*80}\\nModel: {r['Model']}\\n{'='*80}\")\n",
        "    print(r['Generated Summary'])\n"
      ],
      "metadata": {
        "id": "biiIIya3sTW7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}