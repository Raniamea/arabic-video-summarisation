{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOyS6S4woPAV1H1SNNG1rFY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raniamea/arabic-video-summarisation/blob/main/notebooks/01_transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "qOtSkLoSHLpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5121658f-5baa-41ad-e035-99fbc77f057b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Whisper and Torch\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q torch torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "DIUtvDSNHQxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c17ef4f2-e35c-48d2-f0bf-b4facb301c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "\n",
        "# Paths\n",
        "input_dir = \"/content/drive/MyDrive/ArabicVideoSummariser/videos\"\n",
        "output_dir = \"/content/drive/MyDrive/ArabicVideoSummariser/transcripts\"\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load Whisper model\n",
        "model = whisper.load_model(\"large\")  # or \"small\", \"medium\", etc.\n",
        "\n",
        "# Get list of video/audio files\n",
        "video_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.mp4', '.mp3', '.wav', '.m4a'))]\n",
        "\n",
        "print(f\"Found {len(video_files)} files.\")\n",
        "\n",
        "# Loop through files\n",
        "for filename in video_files:\n",
        "    input_path = os.path.join(input_dir, filename)\n",
        "    print(f\"\\n🔄 Transcribing: {filename} ...\")\n",
        "\n",
        "    try:\n",
        "        # Run Whisper transcription\n",
        "        result = model.transcribe(input_path)\n",
        "\n",
        "        # Prepare output path\n",
        "        output_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "        output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "        # Save transcript\n",
        "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(result[\"text\"])\n",
        "\n",
        "        print(f\"✅ Saved transcript to: {output_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to transcribe {filename}: {e}\")\n"
      ],
      "metadata": {
        "id": "4ohmf8d9k0je"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}