{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOyS6S4woPAV1H1SNNG1rFY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raniamea/arabic-video-summarisation/blob/main/notebooks/01_transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "qOtSkLoSHLpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Whisper and Torch\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q torch torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "DIUtvDSNHQxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "\n",
        "# Paths\n",
        "input_dir = \"/content/drive/MyDrive/ArabicVideoSummariser/videos\"\n",
        "output_dir = \"/content/drive/MyDrive/ArabicVideoSummariser/transcripts\"\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load Whisper model\n",
        "model = whisper.load_model(\"large\")  # or \"small\", \"medium\", etc.\n",
        "\n",
        "# Get list of video/audio files\n",
        "video_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.mp4', '.mp3', '.wav', '.m4a'))]\n",
        "\n",
        "print(f\"Found {len(video_files)} files.\")\n",
        "\n",
        "# Loop through files\n",
        "for filename in video_files:\n",
        "    input_path = os.path.join(input_dir, filename)\n",
        "    print(f\"\\nüîÑ Transcribing: {filename} ...\")\n",
        "\n",
        "    try:\n",
        "        # Run Whisper transcription\n",
        "        result = model.transcribe(input_path)\n",
        "\n",
        "        # Prepare output path\n",
        "        output_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "        output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "        # Save transcript\n",
        "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(result[\"text\"])\n",
        "\n",
        "        print(f\"‚úÖ Saved transcript to: {output_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to transcribe {filename}: {e}\")\n"
      ],
      "metadata": {
        "id": "4ohmf8d9k0je"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}