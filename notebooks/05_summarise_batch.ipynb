{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_ZVlNxDg4zEv",
        "XKqvioSm5c2v",
        "PkIKad3wIAFs",
        "P6Gcuh1i1F0I"
      ],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyO0v0kKSWA/RRv3ba2Ogi5e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raniamea/arabic-video-summarisation/blob/main/notebooks/05_summarise_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup"
      ],
      "metadata": {
        "id": "_ZVlNxDg4zEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \\\n",
        "  \"transformers==4.46.3\" \\\n",
        "  \"tokenizers==0.20.3\" \\\n",
        "  \"datasets==2.19.1\" \\\n",
        "  \"evaluate>=0.4.2,<0.5.0\"  \\\n",
        "  \"rouge-score==0.1.2\" \\\n",
        "  \"bert-score==0.3.13\" \\\n",
        "  \"accelerate>=0.30.0,<0.35.0\" \\\n",
        "   sentence-transformers \\\n",
        "  \"sentencepiece>=0.1.99\" \"sacremoses\"\n",
        "\n",
        "!pip install -q evaluate rouge-score sentence-transformers bert-score\n"
      ],
      "metadata": {
        "id": "nehk-m1DhX5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378c654c-b685-46da-a978-01ae2ba17205"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Clean up warning ----\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "id": "bH82LXITov_v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Load Model & Define File Paths"
      ],
      "metadata": {
        "id": "XKqvioSm5c2v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xDiPdtenlriq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ea00bf-4e9d-4f6e-f1e9-345aa2484a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# =========================================================\n",
        "# Mount Google Drive and define base path\n",
        "# =========================================================\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if not os.path.ismount(\"/content/drive\"):\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "# Define base path for project files\n",
        "BASE_PATH = \"/content/drive/MyDrive/ArabicVideoSummariser\"\n",
        "os.makedirs(BASE_PATH, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Obtain Video File Name\n",
        "# =========================================================\n",
        "import os, json\n",
        "\n",
        "params_path = os.path.join(BASE_PATH, \"params.json\")\n",
        "\n",
        "#with open(params_path, \"r\", encoding=\"utf-8\") as f:\n",
        "#    params = json.load(f)\n",
        "\n",
        "#video_filename = params.get(\"video_file\")\n",
        "#assert video_filename, \"params.json must include 'video_file'.\"\n",
        "video_filename=\"Qorsaya.mp4\"\n",
        "\n",
        "video_name  = os.path.splitext(video_filename)[0]"
      ],
      "metadata": {
        "id": "ZaM9UeF_5GsT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Define File Paths & Names\n",
        "# =========================================================\n",
        "validated_path   = os.path.join(BASE_PATH, f\"Validated/Batch/R2/{video_name}\")\n",
        "summaries_path   = os.path.join(BASE_PATH, f\"summaries/Batch/R3/{video_name}\")\n",
        "\n",
        "reference_file= os.path.join(BASE_PATH, f\"summaries/{video_name}_Reference.txt\")\n",
        "excel_out= os.path.join(BASE_PATH, f\"summaries/Batch/R3/{video_name}.xlsx\")\n"
      ],
      "metadata": {
        "id": "NE8sQCEV4ZkW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Load custom trained model\n",
        "# ---------------------------\n",
        "import os, json, re\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "\n",
        "MODEL_PATH = os.path.join(BASE_PATH,\"models/AraBART-finetuned-ar_finetuned_20251110_1546\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)\n"
      ],
      "metadata": {
        "id": "5fdtGOMN9tx-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "PkIKad3wIAFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Arabic Summarization Evaluation (ROUGE + BERTScore + LaBSE)\n",
        "# ============================================================\n",
        "\n",
        "import os, re, torch\n",
        "import evaluate\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# --- Load metrics ---\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "labse = SentenceTransformer(\"sentence-transformers/LaBSE\").to(device)\n",
        "\n",
        "# ============================================\n",
        "# Evaluation Function\n",
        "# ============================================\n",
        "def eval_ar_summary(summary, reference_path=None, *, verbose=False):\n",
        "\n",
        "    with open(reference_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        reference_summary = f.read().strip()\n",
        "\n",
        "    # --- Arabic normalization (light) ---\n",
        "    def normalize_ar(text: str) -> str:\n",
        "        text = re.sub(r\"[\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06ED]\", \"\", text)  # remove diacritics\n",
        "        text = re.sub(r\"[إأآا]\", \"ا\", text)\n",
        "        text = text.replace(\"ى\", \"ي\").replace(\"ة\", \"ه\").replace(\"ؤ\", \"و\").replace(\"ئ\", \"ي\")\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "        return text\n",
        "\n",
        "    ref_norm  = normalize_ar(reference_summary)\n",
        "    pred_norm = normalize_ar(summary)\n",
        "\n",
        "    # --- ROUGE (character-level tokenizer for Arabic) ---\n",
        "    rouge_result = rouge.compute(\n",
        "        predictions=[pred_norm],\n",
        "        references=[ref_norm],\n",
        "        tokenizer=lambda x: list(x)\n",
        "    )\n",
        "\n",
        "    # --- BERTScore ---\n",
        "    bertscore_result = bertscore.compute(\n",
        "        predictions=[pred_norm],\n",
        "        references=[ref_norm],\n",
        "        lang=\"ar\",\n",
        "        model_type=\"xlm-roberta-base\"\n",
        "    )\n",
        "    # --- LaBSE sentence-level similarity ---\n",
        "    ref_emb  = labse.encode([ref_norm],  convert_to_tensor=True, normalize_embeddings=True)\n",
        "    pred_emb = labse.encode([pred_norm], convert_to_tensor=True, normalize_embeddings=True)\n",
        "    labse_score = float(util.cos_sim(pred_emb, ref_emb).item())\n",
        "\n",
        "    metrics = {\n",
        "        \"ROUGE1\": float(rouge_result[\"rouge1\"]),\n",
        "        \"ROUGE2\": float(rouge_result[\"rouge2\"]),\n",
        "        \"ROUGEL\": float(rouge_result[\"rougeL\"]),\n",
        "        \"Precision\": float(bertscore_result[\"precision\"][0]),\n",
        "        \"Recall\": float(bertscore_result[\"recall\"][0]),\n",
        "        \"F1\": float(bertscore_result[\"f1\"][0]),\n",
        "        \"LaBSE\": labse_score,\n",
        "    }\n",
        "\n",
        "    if verbose:\n",
        "        print(\"=== ROUGE Scores ===\")\n",
        "        print(f\"rouge1    : {metrics['ROUGE1']:.4f}\")\n",
        "        print(f\"rouge2    : {metrics['ROUGE2']:.4f}\")\n",
        "        print(f\"rougeL    : {metrics['ROUGEL']:.4f}\")\n",
        "        print(\"\\n=== BERTScore ===\")\n",
        "        print(f\"Precision : {metrics['Precision']:.4f}\")\n",
        "        print(f\"Recall    : {metrics['Recall']:.4f}\")\n",
        "        print(f\"F1        : {metrics['F1']:.4f}\")\n",
        "        print(\"\\n=== LaBSE Semantic Similarity ===\")\n",
        "        print(f\"Sentence-level cosine similarity: {metrics['LaBSE']:.4f}\")\n",
        "        print(\"\\n--- Generated Summary ---\")\n",
        "        print(summary)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# ============================================================\n",
        "# Summarization Function\n",
        "# ============================================================\n",
        "def summarize_file(\n",
        "    input_path: str,\n",
        "    output_path: str,\n",
        "    input_max_len: int = 1024,\n",
        "    max_new_tokens: int = 400,\n",
        "    min_new_tokens: int = 80,\n",
        "    num_beams: int = 4,\n",
        "    no_repeat_ngram_size: int = 3,\n",
        "    length_penalty: float = 1.0,\n",
        "    repetition_penalty: float = 1.2,\n",
        "):\n",
        "    # Safety checks\n",
        "    assert os.path.exists(input_path), f\"Input file not found: {input_path}\"\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device).eval()\n",
        "\n",
        "    # Read input\n",
        "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        full_text = f.read().strip()\n",
        "\n",
        "    if not full_text:\n",
        "        raise ValueError(f\"Input file is empty: {input_path}\")\n",
        "\n",
        "    # Tokenize (truncate if needed)\n",
        "    inputs = tokenizer(\n",
        "        full_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=input_max_len\n",
        "    ).to(device)\n",
        "\n",
        "    # Generate summary\n",
        "    with torch.no_grad():\n",
        "        out_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            min_new_tokens=min_new_tokens,\n",
        "            num_beams=num_beams,\n",
        "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "            length_penalty=length_penalty,\n",
        "            repetition_penalty=repetition_penalty,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "    summary = tokenizer.decode(out_ids[0], skip_special_tokens=True).strip()\n",
        "\n",
        "    # Save\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(summary)\n",
        "\n",
        "    print(f\"\\nSummary saved to: {output_path}\")\n",
        "    eval_ar_summary(summary)\n"
      ],
      "metadata": {
        "id": "Zx1f6S0m_mTT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Summarisation"
      ],
      "metadata": {
        "id": "P6Gcuh1i1F0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Batch Summarization + Save to Excel\n",
        "# ============================================================\n",
        "import os, re\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "results = []\n",
        "\n",
        "# Pattern: Video_SIM0.35_ALFA0.35\n",
        "pattern = re.compile(r\"(?P<video>.+?)_Validated_SIM(?P<SIM>[\\d.]+)_ALFA(?P<ALFA>[\\d.]+)\")\n",
        "\n",
        "# --- Loop through all validated files ---\n",
        "for fname in tqdm(os.listdir(validated_path)):\n",
        "    m = pattern.match(fname)\n",
        "    if not m:\n",
        "        continue\n",
        "\n",
        "    video = m.group(\"video\")\n",
        "    # Clean numeric fields to handle trailing dots or underscores\n",
        "    sim_str = m.group(\"SIM\").rstrip(\".\")\n",
        "    alfa_str = m.group(\"ALFA\").rstrip(\".\")\n",
        "\n",
        "    try:\n",
        "        sim = float(sim_str)\n",
        "        alfa = float(alfa_str)\n",
        "    except ValueError:\n",
        "        print(f\"Skipping file due to bad SIM/ALFA values: {fname}\")\n",
        "        continue\n",
        "\n",
        "    input_path = os.path.join(validated_path, fname)\n",
        "    output_path = os.path.join(summaries_path, f\"{video}_SIM{sim}_ALFA{alfa}_summary.txt\")\n",
        "\n",
        "    # Generate summary\n",
        "    summarize_file(\n",
        "        input_path=input_path,\n",
        "        output_path=output_path,\n",
        "        input_max_len=1024,\n",
        "        max_new_tokens=400,\n",
        "        min_new_tokens=80,\n",
        "        num_beams=4,\n",
        "    )\n",
        "\n",
        "    # Evaluate and collect metrics\n",
        "    with open(output_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        summary_text = f.read().strip()\n",
        "\n",
        "    metrics = eval_ar_summary(summary_text, reference_path=reference_file, verbose=False)\n",
        "\n",
        "    metrics.update({\n",
        "        \"VideoName\": video,\n",
        "        \"ALFA\": alfa,\n",
        "        \"SIM_Threshold\": sim,\n",
        "        \"Generated_Summary\": summary_text,\n",
        "    })\n",
        "    results.append(metrics)\n",
        "\n",
        "# --- Save all results to Excel ---\n",
        "df = pd.DataFrame(results)\n",
        "df.to_excel(excel_out, index=False)\n",
        "print(f\"\\nBatch summarization complete. Results saved to:\\n{excel_out}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrEmuT7b1MYX",
        "outputId": "59bec6e6-531c-4a7e-a587-96970055dc03"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary saved to: /content/drive/MyDrive/ArabicVideoSummariser/summaries/Batch/R3/Qorsaya/Qorsaya_SIM0.2_ALFA0.0_summary.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 1/12 [00:04<00:46,  4.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary saved to: /content/drive/MyDrive/ArabicVideoSummariser/summaries/Batch/R3/Qorsaya/Qorsaya_SIM0.2_ALFA0.2_summary.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 2/12 [00:05<00:26,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary saved to: /content/drive/MyDrive/ArabicVideoSummariser/summaries/Batch/R3/Qorsaya/Qorsaya_SIM0.2_ALFA0.25_summary.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 3/12 [00:07<00:19,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary saved to: /content/drive/MyDrive/ArabicVideoSummariser/summaries/Batch/R3/Qorsaya/Qorsaya_SIM0.2_ALFA0.35_summary.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 4/12 [00:08<00:15,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary saved to: /content/drive/MyDrive/ArabicVideoSummariser/summaries/Batch/R3/Qorsaya/Qorsaya_SIM0.25_ALFA0.0_summary.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 5/12 [00:10<00:12,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary saved to: /content/drive/MyDrive/ArabicVideoSummariser/summaries/Batch/R3/Qorsaya/Qorsaya_SIM0.25_ALFA0.2_summary.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 6/12 [00:12<00:10,  1.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary saved to: /content/drive/MyDrive/ArabicVideoSummariser/summaries/Batch/R3/Qorsaya/Qorsaya_SIM0.25_ALFA0.25_summary.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 7/12 [00:13<00:08,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary saved to: /content/drive/MyDrive/ArabicVideoSummariser/summaries/Batch/R3/Qorsaya/Qorsaya_SIM0.25_ALFA0.35_summary.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 8/12 [00:15<00:06,  1.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary saved to: /content/drive/MyDrive/ArabicVideoSummariser/summaries/Batch/R3/Qorsaya/Qorsaya_SIM0.35_ALFA0.0_summary.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 9/12 [00:16<00:04,  1.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary saved to: /content/drive/MyDrive/ArabicVideoSummariser/summaries/Batch/R3/Qorsaya/Qorsaya_SIM0.35_ALFA0.2_summary.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 10/12 [00:18<00:03,  1.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary saved to: /content/drive/MyDrive/ArabicVideoSummariser/summaries/Batch/R3/Qorsaya/Qorsaya_SIM0.35_ALFA0.25_summary.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 11/12 [00:20<00:01,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary saved to: /content/drive/MyDrive/ArabicVideoSummariser/summaries/Batch/R3/Qorsaya/Qorsaya_SIM0.35_ALFA0.35_summary.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:22<00:00,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch summarization complete. Results saved to:\n",
            "/content/drive/MyDrive/ArabicVideoSummariser/summaries/Batch/R3/Qorsaya.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}