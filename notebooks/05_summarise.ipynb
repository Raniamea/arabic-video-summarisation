{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_ZVlNxDg4zEv",
        "XKqvioSm5c2v",
        "PkIKad3wIAFs"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMvgXVKfuafz8wpuaT+L7px",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raniamea/arabic-video-summarisation/blob/main/notebooks/05_summarise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup"
      ],
      "metadata": {
        "id": "_ZVlNxDg4zEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \\\n",
        "  \"transformers==4.46.3\" \\\n",
        "  \"tokenizers==0.20.3\" \\\n",
        "  \"datasets==2.19.1\" \\\n",
        "  \"evaluate>=0.4.2,<0.5.0\"  \\\n",
        "  \"rouge-score==0.1.2\" \\\n",
        "  \"bert-score==0.3.13\" \\\n",
        "  \"accelerate>=0.30.0,<0.35.0\" \\\n",
        "   sentence-transformers \\\n",
        "  \"sentencepiece>=0.1.99\" \"sacremoses\"\n"
      ],
      "metadata": {
        "id": "nehk-m1DhX5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Load Model & Define File Paths"
      ],
      "metadata": {
        "id": "XKqvioSm5c2v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDiPdtenlriq"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, re\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/ArabicVideoSummariser\"\n",
        "MODEL_PATH = os.path.join(base_path,\"models/AraBART-finetuned-ar_finetuned_20251018_2017\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH)\n",
        "print (\"Loaded\" + MODEL_PATH)"
      ],
      "metadata": {
        "id": "5fdtGOMN9tx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_filename = \"NileTaxi.mp4\"\n",
        "\n",
        "video_name  = os.path.splitext(video_filename)[0]\n",
        "validated_path   = os.path.join(base_path, \"Validated\")\n",
        "transcripts_path   = os.path.join(base_path, \"transcripts\")\n",
        "summaries_path   = os.path.join(base_path, \"summaries\")\n",
        "\n",
        "refrance_file= os.path.join(summaries_path, f\"{video_name}_Refrance.txt\")\n",
        "validated_file=os.path.join(validated_path, f\"{video_name}_result.txt\")\n",
        "transcript_file  = os.path.join(transcripts_path, f\"{video_name}_ar.txt\")\n",
        "validation_SupportScore_results  = os.path.join(validated_path, f\"{video_name}_SupportScore_result.txt\")\n",
        "validation_CosineScore_results  = os.path.join(validated_path, f\"{video_name}_CosineScore_result.txt\")\n",
        "wholesummary_file = os.path.join(summaries_path, f\"{video_name}_WholeSummary.txt\")\n",
        "sceneCosine_summary_file = os.path.join(summaries_path, f\"{video_name}_BasedOnCosineSimilarity_Summary.txt\")\n",
        "sceneSupport_summary_file = os.path.join(summaries_path, f\"{video_name}_BasedOnSupportScore_Summary.txt\")\n"
      ],
      "metadata": {
        "id": "NE8sQCEV4ZkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "PkIKad3wIAFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch\n",
        "import evaluate\n",
        "\n",
        "# --- Load metrics ---\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "\n",
        "# ============================================\n",
        "# Evaluation: ROUGE & BERTScore\n",
        "# ============================================\n",
        "def eval_ar_summary(summary):\n",
        "    with open(refrance_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        reference_summary = f.read().strip()\n",
        "\n",
        "    # --- Arabic normalization (light) ---\n",
        "    def normalize_ar(text: str) -> str:\n",
        "        text = re.sub(r\"[\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06ED]\", \"\", text)  # remove diacritics\n",
        "        text = re.sub(r\"[إأآا]\", \"ا\", text)\n",
        "        text = text.replace(\"ى\", \"ي\").replace(\"ة\", \"ه\").replace(\"ؤ\", \"و\").replace(\"ئ\", \"ي\")\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "        return text\n",
        "\n",
        "    ref_norm = normalize_ar(reference_summary)\n",
        "    pred_norm = normalize_ar(summary)\n",
        "\n",
        "    # --- Compute ROUGE (character-level tokenizer for Arabic) ---\n",
        "    rouge_result = rouge.compute(\n",
        "        predictions=[pred_norm],\n",
        "        references=[ref_norm],\n",
        "        tokenizer=lambda x: list(x)  # char-level tokenization avoids Arabic zero-score issue\n",
        "    )\n",
        "\n",
        "    print(\"=== ROUGE Scores ===\")\n",
        "    for k, v in rouge_result.items():\n",
        "        print(f\"{k:10s}: {v:.4f}\")\n",
        "\n",
        "    # --- Compute BERTScore ---\n",
        "    bertscore_result = bertscore.compute(\n",
        "        predictions=[pred_norm],\n",
        "        references=[ref_norm],\n",
        "        lang=\"ar\",                     # keep language flag\n",
        "        model_type=\"xlm-roberta-base\"  # Arabic-friendly model\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== BERTScore ===\")\n",
        "    print(f\"Precision : {bertscore_result['precision'][0]:.4f}\")\n",
        "    print(f\"Recall    : {bertscore_result['recall'][0]:.4f}\")\n",
        "    print(f\"F1        : {bertscore_result['f1'][0]:.4f}\")\n",
        "\n",
        "    print(summary)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Helper: Summarize a text file and save output\n",
        "# ============================================================\n",
        "def summarize_file(\n",
        "    input_path: str,\n",
        "    output_path: str,\n",
        "    input_max_len: int = 1024,\n",
        "    max_new_tokens: int = 400,\n",
        "    min_new_tokens: int = 80,\n",
        "    num_beams: int = 4,\n",
        "    no_repeat_ngram_size: int = 3,\n",
        "    length_penalty: float = 1.0,\n",
        "):\n",
        "    # Safety checks\n",
        "    assert os.path.exists(input_path), f\"Input file not found: {input_path}\"\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device).eval()\n",
        "\n",
        "    # Read input\n",
        "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        full_text = f.read().strip()\n",
        "\n",
        "    if not full_text:\n",
        "        raise ValueError(f\"Input file is empty: {input_path}\")\n",
        "\n",
        "    # Encode (will truncate to input_max_len by request)\n",
        "    inputs = tokenizer(\n",
        "        full_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=input_max_len\n",
        "    ).to(device)\n",
        "\n",
        "    # Generate\n",
        "    with torch.no_grad():\n",
        "        out_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            min_new_tokens=min_new_tokens,\n",
        "            num_beams=num_beams,\n",
        "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "            length_penalty=length_penalty,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "    summary = tokenizer.decode(out_ids[0], skip_special_tokens=True).strip()\n",
        "\n",
        "    # Save\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(summary)\n",
        "\n",
        "    print(f\"Summary saved to: {output_path}\")\n",
        "    eval_ar_summary(summary)"
      ],
      "metadata": {
        "id": "kHAPt-m2omT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Video Summarisation"
      ],
      "metadata": {
        "id": "3C-hHi4Pu-NO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Summarize Full Transcript\n",
        "# ============================\n",
        "summarize_file(\n",
        "    input_path=transcript_file,\n",
        "    output_path=wholesummary_file,        # where to save the summary\n",
        "    input_max_len=1024,\n",
        "    max_new_tokens=400,\n",
        "    min_new_tokens=80,\n",
        "    num_beams=4,\n",
        ")"
      ],
      "metadata": {
        "id": "MvmhBGmkLLUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Summarize Validated Cosine Similarity transcript\n",
        "# ============================\n",
        "summarize_file(\n",
        "    input_path=validation_CosineScore_results,\n",
        "    output_path=sceneCosine_summary_file,\n",
        "    input_max_len=1024,\n",
        "    max_new_tokens=400,\n",
        "    min_new_tokens=80,\n",
        "    num_beams=4,\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZBiFEwvBB3Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Summarize Validated fused score (cosine + lexical) transcript\n",
        "# ============================\n",
        "summarize_file(\n",
        "    input_path=validation_SupportScore_results,\n",
        "    output_path=sceneSupport_summary_file,\n",
        "    input_max_len=1024,\n",
        "    max_new_tokens=400,\n",
        "    min_new_tokens=80,\n",
        "    num_beams=4,\n",
        ")"
      ],
      "metadata": {
        "id": "o8umVjoSXqRJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}