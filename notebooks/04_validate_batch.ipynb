{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raniamea/arabic-video-summarisation/blob/main/notebooks/04_validate_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oavdO_LK9djT"
      },
      "source": [
        "# Batch Validation using ASR Generated Transcript & Arabic Captions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJZes0KgR5_i"
      },
      "outputs": [],
      "source": [
        "!pip install -q --no-cache-dir torch==2.6.0\n",
        "!pip install -q --no-cache-dir transformers==4.44.2 sentence-transformers==2.6.1\n",
        "!pip install -q --no-cache-dir numpy==1.26.4 tqdm==4.67.1\n",
        "!pip install -q torch torchvision torchaudio sentence-transformers evaluate rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RkpFfleJ_7OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c7333b-d335-41f7-b6c7-3c581ca7be8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# =========================================================\n",
        "# Mount Google Drive and define base path\n",
        "# =========================================================\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if not os.path.ismount(\"/content/drive\"):\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "# Define base path for project files\n",
        "BASE_PATH = \"/content/drive/MyDrive/ArabicVideoSummariser\"\n",
        "os.makedirs(BASE_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Obtain Video File Name\n",
        "# =========================================================\n",
        "import os, json\n",
        "\n",
        "params_path = os.path.join(BASE_PATH, \"params.json\")\n",
        "\n",
        "#with open(params_path, \"r\", encoding=\"utf-8\") as f:\n",
        "#    params = json.load(f)\n",
        "\n",
        "#video_filename = params.get(\"video_file\")\n",
        "#assert video_filename, \"params.json must include 'video_file'.\"\n",
        "video_filename=\"FeathersOfFortune.mp4\"\n",
        "\n",
        "video_name  = os.path.splitext(video_filename)[0]"
      ],
      "metadata": {
        "id": "BrxhEq3I2FK3"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Define File Paths & Names\n",
        "# =========================================================\n",
        "videos_path      = os.path.join(BASE_PATH, \"videos\")\n",
        "captions_path    = os.path.join(BASE_PATH, \"captions\")\n",
        "preprocessed_path= os.path.join(BASE_PATH, \"Preprocessed\")\n",
        "validated_path   = os.path.join(BASE_PATH, \"Validated\")\n",
        "os.makedirs(validated_path, exist_ok=True)\n",
        "\n",
        "caption_path   = os.path.join(captions_path,   f\"{video_name}.json\")\n",
        "transcript_path= os.path.join(preprocessed_path, f\"{video_name}_CleanTranscript.json\")\n",
        "merged_file= os.path.join(validated_path, f\"{video_name}_ScenesIntervalTranscripts_WA.json\")\n",
        "strict_file= os.path.join(validated_path, f\"{video_name}_ScenesIntervalTranscripts_SA.json\")\n",
        "assert os.path.exists(caption_path),   f\"Missing captions file: {caption_path}\"\n",
        "assert os.path.exists(transcript_path),f\"Missing transcript file: {transcript_path}\"\n",
        "\n"
      ],
      "metadata": {
        "id": "X_QT-vxh13Us"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "5fdtGOMN9tx-"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Load multilingual SBERT model\n",
        "# ---------------------------\n",
        "import os, json, re\n",
        "import numpy as np\n",
        "from bisect import bisect_left, bisect_right\n",
        "from typing import List, Dict, Any, Tuple, Iterable\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "MODEL_ID = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = SentenceTransformer(MODEL_ID, device=device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Allignment"
      ],
      "metadata": {
        "id": "lxa-NvP3Zgd2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRLZKzGy6C6O"
      },
      "source": [
        "## Strict Allignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "l7NUSL745rYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff019916-d318-455c-b594-7e521ff5d74a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strict alignment saved: /content/drive/MyDrive/ArabicVideoSummariser/Validated/FeathersOfFortune_ScenesIntervalTranscripts_SA.json\n",
            "Updated captions for 177 transcript segments.\n"
          ]
        }
      ],
      "source": [
        "import json, os\n",
        "\n",
        "# --- Load & prep ---\n",
        "with open(transcript_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    transcripts = json.load(f)\n",
        "\n",
        "with open(caption_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    captions_data = json.load(f)\n",
        "\n",
        "# --- Extract scene times and texts from the caption file ---\n",
        "scene_times = []\n",
        "scene_texts_en = []\n",
        "scene_texts_ar = []\n",
        "\n",
        "for key, val in captions_data.items():\n",
        "    if \"scene_time\" in val:\n",
        "        scene_times.append(float(val[\"scene_time\"]))\n",
        "        scene_texts_en.append((val.get(\"english\") or \"\").strip())\n",
        "        scene_texts_ar.append((val.get(\"arabic\") or \"\").strip())\n",
        "\n",
        "# --- Add captions to each transcript segment ---\n",
        "for segment in transcripts[\"segments\"]:\n",
        "    start = float(segment.get(\"start\", 0))\n",
        "    end   = float(segment.get(\"end\", 0))\n",
        "\n",
        "    in_window = [i for i, t in enumerate(scene_times) if start <= t < end]\n",
        "    en_strings = [scene_texts_en[i] for i in in_window] if in_window else []\n",
        "    ar_strings = [scene_texts_ar[i] for i in in_window] if in_window else []\n",
        "\n",
        "    # joined strings + raw lists (non-breaking additions)\n",
        "    segment[\"captions_en\"] = \" \".join([s for s in en_strings if s]).strip()\n",
        "    segment[\"captions_ar\"] = \" \".join([s for s in ar_strings if s]).strip()\n",
        "\n",
        "# --- Save the updated transcript ---\n",
        "with open(strict_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(transcripts, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Strict alignment saved: {strict_file}\")\n",
        "print(f\"Updated captions for {len(transcripts['segments'])} transcript segments.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nPhDQ1E5SG9"
      },
      "source": [
        "## Scene-Based Sliding-Window Alignment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# --- Load data ---\n",
        "with open(transcript_path, 'r', encoding='utf-8') as f:\n",
        "    transcripts = json.load(f)\n",
        "with open(caption_path, 'r', encoding='utf-8') as f:\n",
        "    captions_data = json.load(f)\n",
        "\n",
        "# --- Build sorted caption lists ---\n",
        "scene_items = sorted(\n",
        "    (\n",
        "        (\n",
        "            float(item['scene_time']),\n",
        "            (item.get('english') or '').strip(),\n",
        "            (item.get('arabic')  or '').strip(),\n",
        "        )\n",
        "        for item in captions_data.values()\n",
        "    ),\n",
        "    key=lambda x: x[0]\n",
        ")\n",
        "\n",
        "scene_times = [t for t, _, _ in scene_items]\n",
        "scene_texts_en = [en for _, en, _ in scene_items]\n",
        "scene_texts_ar = [ar for _, _, ar in scene_items]\n",
        "\n",
        "# --- Align captions with transcript segments ---\n",
        "for segment in transcripts['segments']:\n",
        "    start = float(segment.get('start', 0))\n",
        "    end   = float(segment.get('end', 0))\n",
        "\n",
        "    # Find all captions that fall within this segment’s time window\n",
        "    in_window = [i for i, t in enumerate(scene_times) if start <= t < end]\n",
        "\n",
        "    gathered_en, gathered_ar = [], []\n",
        "\n",
        "    # Always include immediate previous and next captions by index\n",
        "    if in_window:\n",
        "        first_idx = min(in_window)\n",
        "        last_idx  = max(in_window)\n",
        "    else:\n",
        "        # If no captions fall in the window, pick nearest caption by time\n",
        "        nearest_idx = min(range(len(scene_times)), key=lambda i: abs(scene_times[i] - start))\n",
        "        first_idx = last_idx = nearest_idx\n",
        "\n",
        "    # Caption immediately before\n",
        "    prev_idx = first_idx - 1 if first_idx > 0 else None\n",
        "    if prev_idx is not None:\n",
        "        gathered_en.append(scene_texts_en[prev_idx])\n",
        "        gathered_ar.append(scene_texts_ar[prev_idx])\n",
        "\n",
        "    # Captions inside the window\n",
        "    gathered_en.extend(scene_texts_en[i] for i in range(first_idx, last_idx + 1))\n",
        "    gathered_ar.extend(scene_texts_ar[i] for i in range(first_idx, last_idx + 1))\n",
        "\n",
        "    # Caption immediately after\n",
        "    next_idx = last_idx + 1 if last_idx + 1 < len(scene_texts_en) else None\n",
        "    if next_idx is not None:\n",
        "        gathered_en.append(scene_texts_en[next_idx])\n",
        "        gathered_ar.append(scene_texts_ar[next_idx])\n",
        "\n",
        "    # Join captions\n",
        "    segment['captions_en'] = ' '.join([s for s in gathered_en if s]).strip()\n",
        "    segment['captions_ar'] = ' '.join([s for s in gathered_ar if s]).strip()\n",
        "\n",
        "# --- Save updated file ---\n",
        "with open(merged_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(transcripts, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Updated captions for {len(transcripts['segments'])} transcript segments\")\n",
        "print(f\"Saved to {merged_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rovY8qJSLUF5",
        "outputId": "6d174c71-ced9-4008-a742-a49f00006f6d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated captions for 177 transcript segments\n",
            "Saved to /content/drive/MyDrive/ArabicVideoSummariser/Validated/FeathersOfFortune_ScenesIntervalTranscripts_WA.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "dcSaT9HOQ-1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# CONFIG\n",
        "# ==============================\n",
        "KEEP_MARGIN = 0.15\n",
        "ALFA_GRID = [0.0, 0.2, 0.25, 0.35]\n",
        "THRESH_GRID = [0.2, 0.25, 0.35]\n"
      ],
      "metadata": {
        "id": "xBx1xYJKMj_d"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "-3sOtjNTRIIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "SC0Ez9-sX18Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "# ==============================\n",
        "# Arabic  ROUGE\n",
        "# ==============================\n",
        "rouge_metric = evaluate.load(\"rouge\")\n",
        "\n",
        "\n",
        "def arabic_rouge_score(pred_text, ref_text):\n",
        "    from evaluate import load\n",
        "    rouge_metric = load(\"rouge\")\n",
        "    scores = rouge_metric.compute(\n",
        "        predictions=[pred_text],\n",
        "        references=[ref_text],\n",
        "        tokenizer=lambda x: list(x)\n",
        "    )\n",
        "    return (scores[\"rouge1\"] + scores[\"rouge2\"] + scores[\"rougeL\"]) / 3.0\n",
        "\n",
        "def compute_fusion_score(lexical, cosine):\n",
        "    return ALFA_FUSION * lexical + (1 - ALFA_FUSION) * cosine\n",
        "\n",
        "# ==============================\n",
        "# Field getters\n",
        "# ==============================\n",
        "def first_nonempty(rec, keys):\n",
        "    for k in keys:\n",
        "        v = rec.get(k)\n",
        "        if isinstance(v, str) and v.strip():\n",
        "            return v.strip()\n",
        "    return \"\"\n",
        "\n",
        "def get_seg_text(rec):\n",
        "    return first_nonempty(rec, [\n",
        "        \"transcript_text\", \"text_norm\", \"original\", \"text\", \"segment_text\"\n",
        "    ])\n",
        "\n",
        "def get_caption_en(rec):\n",
        "    \"\"\"English captions for semantic validation.\"\"\"\n",
        "    return first_nonempty(rec, [\n",
        "        \"captions_en\", \"english_caption\", \"caption_en\", \"captionsEnglish\"\n",
        "    ])\n",
        "\n",
        "def get_caption_ar(rec):\n",
        "    \"\"\"Arabic captions for lexical validation.\"\"\"\n",
        "    return first_nonempty(rec, [\n",
        "        \"captions_ar\", \"caption_ar\", \"captionsArabic\", \"captions\", \"scene_caption\",\n",
        "        \"visual_caption\", \"blip_caption\", \"clip_caption\", \"yolo_caption\"\n",
        "    ])\n",
        "\n",
        "def get_lemma_text(rec):\n",
        "    lemmas = rec.get(\"lemmas\")\n",
        "    if isinstance(lemmas, list) and lemmas:\n",
        "        return \" \".join(map(str, lemmas))\n",
        "    return \"\"\n",
        "\n",
        "# ==============================\n",
        "# Stopwords & POS helpers\n",
        "# ==============================\n",
        "AR_STOPWORDS = {\n",
        "    \"و\",\"في\",\"على\",\"من\",\"إلى\",\"عن\",\"أن\",\"إن\",\"كان\",\"كانت\",\"يكون\",\"مع\",\"هذا\",\"هذه\",\n",
        "    \"ذلك\",\"تلك\",\"هناك\",\"هنا\",\"هو\",\"هي\",\"هم\",\"هن\",\"كما\",\"لكن\",\"بل\",\"قد\",\"تم\",\"ثم\",\n",
        "    \"كل\",\"أي\",\"أو\",\"أمام\",\"خلال\",\"بعد\",\"قبل\",\"حتى\",\"حيث\",\"إذا\",\"إنما\",\"إما\",\"لدى\",\n",
        "    \"لدي\",\"لها\",\"له\",\"لهم\",\"لنا\",\"ما\",\"ماذا\",\"لماذا\",\"كيف\",\"متى\",\"أيضا\",\"بدون\",\"أمام\",\n",
        "    \"داخل\",\"خارج\",\"بين\",\"أكثر\",\"أقل\"\n",
        "}\n",
        "\n",
        "def is_propn(pos_tag):\n",
        "    return \"NOUN\" in str(pos_tag).upper()\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# Safe JSON serialization\n",
        "# ==============================\n",
        "def to_serializable(obj):\n",
        "    if isinstance(obj, (np.integer,)):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, (np.floating,)):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, (np.bool_,)):\n",
        "        return bool(obj)\n",
        "    elif isinstance(obj, torch.Tensor):\n",
        "        return obj.item()\n",
        "    return str(obj)\n"
      ],
      "metadata": {
        "id": "mccbFU8MXx_m"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Validation Function"
      ],
      "metadata": {
        "id": "_-b7FxHYghW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Main validation\n",
        "# ==============================\n",
        "def validate_words_by_visual_support(\n",
        "    records\n",
        "):\n",
        "    enriched = []\n",
        "\n",
        "    for rec in tqdm(records):\n",
        "        seg_text = get_seg_text(rec)\n",
        "        seg_lemma_text = get_lemma_text(rec) or seg_text\n",
        "\n",
        "        cap_en = get_caption_en(rec)   # English for semantic\n",
        "        cap_ar = get_caption_ar(rec)   # Arabic for lexical\n",
        "\n",
        "        rec_out = dict(rec)\n",
        "        rec_out[\"validated_text\"] = seg_text\n",
        "        rec_out[\"cosine_score\"] = 0.0\n",
        "\n",
        "        # --- Semantic similarity ---\n",
        "        if cap_en and seg_lemma_text:\n",
        "            with torch.no_grad():\n",
        "                seg_emb = model.encode(seg_lemma_text, convert_to_tensor=True)\n",
        "                cap_emb = model.encode(cap_en, convert_to_tensor=True)\n",
        "                cosine_val = float(util.cos_sim(seg_emb, cap_emb).item())\n",
        "            rec_out[\"cosine_score\"] = cosine_val\n",
        "        else:\n",
        "            cosine_val = 0.0\n",
        "\n",
        "        # --- Lexical similarity ---\n",
        "        tokens = rec.get(\"tokens\", [])\n",
        "        seg_joined = \" \".join(tokens) if tokens else seg_lemma_text\n",
        "        lex = arabic_rouge_score(seg_joined, cap_ar) if cap_ar and seg_joined else 0.0\n",
        "\n",
        "\n",
        "        # --- Fusion score ---\n",
        "        fused = compute_fusion_score(lex, cosine_val)\n",
        "        rec_out[\"scores\"] = {\n",
        "            \"cosine\": float(cosine_val),\n",
        "            \"lexical_rouge\": float(lex),\n",
        "            \"fused\": float(fused)\n",
        "        }\n",
        "\n",
        "        #Named Entity flag (using CAMeL NER output) + margin value ---\n",
        "        named_entities = rec.get(\"named_entities\") or []\n",
        "        has_named_entity = bool(named_entities)  # True if any named entity present\n",
        "        #Numeric margin per record -> KEEP_MARGIN if NOUN present, else 0.0\n",
        "        rec_out[\"Propn_Keep_Margin\"] = float(KEEP_MARGIN) if has_named_entity else 0.0\n",
        "\n",
        "        enriched.append(rec_out)\n",
        "\n",
        "    summary = {\n",
        "        \"records\": len(enriched),\n",
        "        \"Proper_Keep_true\": sum(1 for r in enriched if r.get(\"Proper_Keep\")),\n",
        "        \"params\": {\n",
        "            \"alpha_fusion\": ALFA_FUSION,\n",
        "            \"keep_margin\": KEEP_MARGIN,\n",
        "            \"model\": MODEL_ID\n",
        "        }\n",
        "    }\n",
        "    return enriched, summary\n"
      ],
      "metadata": {
        "id": "o-8GgBx-geSA"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Validation"
      ],
      "metadata": {
        "id": "VzXiCfczQgwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Batch Validation\n",
        "# ==========================================\n",
        "import json, os\n",
        "\n",
        "def _fmt2(x: float) -> str:\n",
        "    return f\"{x:.2f}\"\n",
        "\n",
        "for alpha in ALFA_GRID:\n",
        "    for thresh in THRESH_GRID:\n",
        "        ALFA_FUSION   = alpha\n",
        "        SIM_THRESHOLD = thresh\n",
        "\n",
        "        tag = f\"SIM{_fmt2(SIM_THRESHOLD)}_ALFA{_fmt2(ALFA_FUSION)}\"\n",
        "\n",
        "        # Run validation on Strict Allighnment file\n",
        "        with open(strict_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            data_sa = json.load(f)\n",
        "        recs_sa = data_sa.get(\"scenes\") or data_sa.get(\"segments\") or data_sa\n",
        "\n",
        "        enriched_sa, stats_sa = validate_words_by_visual_support(records=recs_sa)\n",
        "\n",
        "        validated_alignment_SA_cfg = os.path.join(\n",
        "            validated_path, f\"{video_name}_Validated_SA_{tag}.json\"\n",
        "        )\n",
        "        with open(validated_alignment_SA_cfg, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(\n",
        "                {\"summary\": {**stats_sa, \"alpha_fusion\": ALFA_FUSION},\n",
        "                 \"records\": enriched_sa},\n",
        "                f, ensure_ascii=False, indent=2, default=to_serializable\n",
        "            )\n",
        "\n",
        "        # Run validation on Windowed Allighnment file\n",
        "        with open(merged_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            data_wa = json.load(f)\n",
        "        recs_wa = data_wa.get(\"scenes\") or data_wa.get(\"segments\") or data_wa\n",
        "\n",
        "        enriched_wa, stats_wa = validate_words_by_visual_support(records=recs_wa)\n",
        "\n",
        "        validated_alignment_WA_cfg = os.path.join(\n",
        "            validated_path, f\"{video_name}_Validated_WA_{tag}.json\"\n",
        "        )\n",
        "        with open(validated_alignment_WA_cfg, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(\n",
        "                {\"summary\": {**stats_wa, \"alpha_fusion\": ALFA_FUSION},\n",
        "                 \"records\": enriched_wa},\n",
        "                f, ensure_ascii=False, indent=2, default=to_serializable\n",
        "            )\n",
        "\n",
        "        # Combine STRICT + WINDOW by higher cosine\n",
        "        with open(validated_alignment_SA_cfg, \"r\", encoding=\"utf-8\") as f:\n",
        "            strict_data = json.load(f)\n",
        "        with open(validated_alignment_WA_cfg, \"r\", encoding=\"utf-8\") as f:\n",
        "            window_data = json.load(f)\n",
        "\n",
        "        strict_segments = strict_data.get(\"records\") or strict_data.get(\"segments\") or strict_data.get(\"scenes\") or []\n",
        "        window_segments = window_data.get(\"records\") or window_data.get(\"segments\") or window_data.get(\"scenes\") or []\n",
        "\n",
        "        combined_records = []\n",
        "        common_len = min(len(strict_segments), len(window_segments))\n",
        "        num_from_strict = 0\n",
        "        num_from_window = 0\n",
        "\n",
        "        for i in range(common_len):\n",
        "            s_rec = strict_segments[i]\n",
        "            w_rec = window_segments[i]\n",
        "\n",
        "            s_scores = s_rec.get(\"scores\") or {}\n",
        "            w_scores = w_rec.get(\"scores\") or {}\n",
        "\n",
        "            s_cosine = float(s_scores.get(\"cosine\", 0.0) or 0.0)\n",
        "            w_cosine = float(w_scores.get(\"cosine\", 0.0) or 0.0)\n",
        "\n",
        "            choose_window = (w_cosine > s_cosine)  # same criterion as before\n",
        "            best = w_rec if choose_window else s_rec\n",
        "\n",
        "            combined_records.append(dict(best))\n",
        "            num_from_window += int(choose_window)\n",
        "            num_from_strict += int(not choose_window)\n",
        "\n",
        "        combined_summary = {\n",
        "            \"records_total\": len(combined_records),\n",
        "            \"source_files\": {\"strict\": validated_alignment_SA_cfg, \"window\": validated_alignment_WA_cfg},\n",
        "            \"selection_criterion\": \"highest cosine score per segment\",\n",
        "            \"chosen_source_counts\": {\"from_strict\": num_from_strict, \"from_window\": num_from_window},\n",
        "            \"alpha_fusion\": ALFA_FUSION,\n",
        "            \"sim_threshold\": SIM_THRESHOLD\n",
        "        }\n",
        "\n",
        "        validated_alignment_cfg = os.path.join(\n",
        "            validated_path, f\"{video_name}_Validated_{tag}.json\"\n",
        "        )\n",
        "        with open(validated_alignment_cfg, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump({\"summary\": combined_summary, \"records\": combined_records},\n",
        "                      f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        # Select & concatenate using fusion_score > SIM_THRESHOLD - margin\n",
        "        selected_segments = []\n",
        "        for rec in combined_records:\n",
        "            scores = rec.get(\"scores\", {})\n",
        "            fusion_score = float(scores.get(\"fused\", 0.0))\n",
        "            margin = float(rec.get(\"Propn_Keep_Margin\", 0.0) or 0.0)\n",
        "\n",
        "            text = (rec.get(\"validated_text\") or rec.get(\"transcript_text\") or rec.get(\"text\") or \"\").strip()\n",
        "\n",
        "            if fusion_score > SIM_THRESHOLD - margin:\n",
        "                if text:\n",
        "                    selected_segments.append(text)\n",
        "\n",
        "        validated_text_all = \" \".join(selected_segments).strip()\n",
        "        validated_result_cfg = os.path.join(\n",
        "            validated_path, f\"Batch/R3/{video_name}/{video_name}_Validated_{tag}.txt\"\n",
        "        )\n",
        "        with open(validated_result_cfg, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(validated_text_all)\n",
        "\n",
        "        print(f\"[{tag}] Saved File → {validated_result_cfg}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekr7QwZEmAnR",
        "outputId": "0819796e-9eb8-42b9-a394-504844037f4c"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 177/177 [01:06<00:00,  2.67it/s]\n",
            "100%|██████████| 177/177 [01:52<00:00,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SIM0.20_ALFA0.00] Saved File → /content/drive/MyDrive/ArabicVideoSummariser/Validated/Batch/R3/FeathersOfFortune/FeathersOfFortune_Validated_SIM0.20_ALFA0.00.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 177/177 [01:05<00:00,  2.68it/s]\n",
            "100%|██████████| 177/177 [01:52<00:00,  1.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SIM0.25_ALFA0.00] Saved File → /content/drive/MyDrive/ArabicVideoSummariser/Validated/Batch/R3/FeathersOfFortune/FeathersOfFortune_Validated_SIM0.25_ALFA0.00.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 177/177 [01:06<00:00,  2.67it/s]\n",
            "100%|██████████| 177/177 [01:51<00:00,  1.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SIM0.35_ALFA0.00] Saved File → /content/drive/MyDrive/ArabicVideoSummariser/Validated/Batch/R3/FeathersOfFortune/FeathersOfFortune_Validated_SIM0.35_ALFA0.00.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 177/177 [01:06<00:00,  2.68it/s]\n",
            "100%|██████████| 177/177 [01:51<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SIM0.20_ALFA0.20] Saved File → /content/drive/MyDrive/ArabicVideoSummariser/Validated/Batch/R3/FeathersOfFortune/FeathersOfFortune_Validated_SIM0.20_ALFA0.20.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 177/177 [01:06<00:00,  2.66it/s]\n",
            "100%|██████████| 177/177 [01:51<00:00,  1.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SIM0.25_ALFA0.20] Saved File → /content/drive/MyDrive/ArabicVideoSummariser/Validated/Batch/R3/FeathersOfFortune/FeathersOfFortune_Validated_SIM0.25_ALFA0.20.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 177/177 [01:06<00:00,  2.67it/s]\n",
            "100%|██████████| 177/177 [01:52<00:00,  1.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SIM0.35_ALFA0.20] Saved File → /content/drive/MyDrive/ArabicVideoSummariser/Validated/Batch/R3/FeathersOfFortune/FeathersOfFortune_Validated_SIM0.35_ALFA0.20.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 177/177 [01:06<00:00,  2.67it/s]\n",
            "100%|██████████| 177/177 [01:52<00:00,  1.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SIM0.20_ALFA0.25] Saved File → /content/drive/MyDrive/ArabicVideoSummariser/Validated/Batch/R3/FeathersOfFortune/FeathersOfFortune_Validated_SIM0.20_ALFA0.25.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 177/177 [01:06<00:00,  2.68it/s]\n",
            "100%|██████████| 177/177 [01:52<00:00,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SIM0.25_ALFA0.25] Saved File → /content/drive/MyDrive/ArabicVideoSummariser/Validated/Batch/R3/FeathersOfFortune/FeathersOfFortune_Validated_SIM0.25_ALFA0.25.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 177/177 [01:06<00:00,  2.68it/s]\n",
            "100%|██████████| 177/177 [01:52<00:00,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SIM0.35_ALFA0.25] Saved File → /content/drive/MyDrive/ArabicVideoSummariser/Validated/Batch/R3/FeathersOfFortune/FeathersOfFortune_Validated_SIM0.35_ALFA0.25.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 177/177 [01:06<00:00,  2.66it/s]\n",
            "100%|██████████| 177/177 [01:50<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SIM0.20_ALFA0.35] Saved File → /content/drive/MyDrive/ArabicVideoSummariser/Validated/Batch/R3/FeathersOfFortune/FeathersOfFortune_Validated_SIM0.20_ALFA0.35.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 177/177 [01:06<00:00,  2.68it/s]\n",
            "100%|██████████| 177/177 [01:51<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SIM0.25_ALFA0.35] Saved File → /content/drive/MyDrive/ArabicVideoSummariser/Validated/Batch/R3/FeathersOfFortune/FeathersOfFortune_Validated_SIM0.25_ALFA0.35.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 177/177 [01:05<00:00,  2.70it/s]\n",
            "100%|██████████| 177/177 [01:51<00:00,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SIM0.35_ALFA0.35] Saved File → /content/drive/MyDrive/ArabicVideoSummariser/Validated/Batch/R3/FeathersOfFortune/FeathersOfFortune_Validated_SIM0.35_ALFA0.35.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "oavdO_LK9djT",
        "lxa-NvP3Zgd2",
        "dcSaT9HOQ-1B",
        "SC0Ez9-sX18Y",
        "_-b7FxHYghW6"
      ],
      "gpuType": "L4",
      "provenance": [],
      "authorship_tag": "ABX9TyMfkhP0dY11ysevDVCOwUbq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}