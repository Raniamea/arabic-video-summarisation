{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raniamea/arabic-video-summarisation/blob/main/VideoProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa355c80",
      "metadata": {
        "id": "aa355c80"
      },
      "source": [
        "# 🎥 Arabic Video Multimodal Validator and Summarizer\n",
        "\n",
        "This Colab notebook lets you input the name of an Arabic video file and automatically performs:\n",
        "- Audio transcription (Arabic)\n",
        "- Scene/keyframe caption validation using Sentence-BERT and CLIP\n",
        "- (Optional) Abstractive summarization with mBART\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔊 1. Setup Environment"
      ],
      "metadata": {
        "id": "_z2ibBr631mn"
      },
      "id": "_z2ibBr631mn"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ebf7362d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebf7362d",
        "outputId": "d1c50e1b-bdf2-4186-a115-64608779dad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install Whisper and Torch\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q torch torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q transformers sentence-transformers torchaudio opencv-python Pillow\n",
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "# Unmount first\n",
        "!fusermount -u /content/drive || echo \"Already unmounted\"\n",
        "\n",
        "# Delete the mount folder entirely\n",
        "!rm -rf /content/drive\n",
        "\n",
        "# Now mount again\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dTq6hem-Mwn",
        "outputId": "a63fa58e-3dc7-49e5-c628-f114db32b15c"
      },
      "id": "-dTq6hem-Mwn",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusermount: failed to unmount /content/drive: Invalid argument\n",
            "Already unmounted\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define base paths\n",
        "base_path = \"/content/drive/MyDrive/ArabicVideoSummariser\"\n",
        "videos_path = os.path.join(base_path, \"videos\")\n",
        "transcripts_path = os.path.join(base_path, \"transcripts\")\n",
        "captions_path = os.path.join(base_path, \"captions\")\n",
        "keyframes_path = os.path.join(base_path, \"keyframes\")\n",
        "os.makedirs(transcripts_path, exist_ok=True)\n",
        "os.makedirs(captions_path, exist_ok=True)\n",
        "os.makedirs(keyframes_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "MtOIIp158Tdz"
      },
      "id": "MtOIIp158Tdz",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔊 2. Input Video Filename"
      ],
      "metadata": {
        "id": "kJfBHPBq3nqm"
      },
      "id": "kJfBHPBq3nqm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Video Filename\n",
        "video_filename = input(\"Enter the name of the video file (e.g., MyVideo.mp4): \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x1rnSV02iD4",
        "outputId": "33e2cde8-1d02-4c87-ca63-88be723041ce"
      },
      "id": "-x1rnSV02iD4",
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the name of the video file (e.g., MyVideo.mp4): Calligraphy.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = os.path.join(videos_path, video_filename)\n",
        "assert os.path.exists(video_path), f\"Video file not found: {video_path}\"\n"
      ],
      "metadata": {
        "id": "zsXhIfDs4kO5"
      },
      "id": "zsXhIfDs4kO5",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31fa5413",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31fa5413",
        "outputId": "adde5d2b-d25d-43c2-d373-34dec652d77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [01:19<00:00, 38.9MiB/s]\n"
          ]
        }
      ],
      "source": [
        "# Transcribe the video\n",
        "import whisper\n",
        "# Load Whisper model\n",
        "model = whisper.load_model(\"large\", device=\"cuda\")\n",
        "\n",
        "# transcribe (Arabic)\n",
        "result = model.transcribe(video_path, language=\"ar\", task=\"transcribe\")\n",
        "transcript_txt = os.path.join(transcripts_path, f\"{os.path.splitext(video_filename)[0]}_ar.txt\")\n",
        "with open(transcript_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(result['text'])\n",
        "print(f\"✅ Saved Arabic transcript to: {transcript_txt}\")\n",
        "\n",
        "\n",
        "# Translate (Arabic → English)\n",
        "result_en = model.transcribe(video_path, language=\"ar\", task=\"translate\")\n",
        "translation_txt = os.path.join(transcripts_path, f\"{os.path.splitext(video_filename)[0]}_en.txt\")\n",
        "with open(translation_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(result_en[\"text\"])\n",
        "print(f\"✅ Saved English translation to: {translation_txt}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eef4a65b",
      "metadata": {
        "id": "eef4a65b"
      },
      "source": [
        "# 🧠 4. Process Transcript into Overlapping Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa7a3d4",
      "metadata": {
        "id": "1aa7a3d4"
      },
      "outputs": [],
      "source": [
        "# Load transcript and split into chunks\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "with open(transcript_txt, encoding='utf-8') as f:\n",
        "    full_transcript = f.read()\n",
        "\n",
        "words = word_tokenize(full_transcript)\n",
        "chunk_size = 30\n",
        "step = 15\n",
        "transcript_chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words)-chunk_size, step)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fd49d45",
      "metadata": {
        "id": "8fd49d45"
      },
      "source": [
        "# 🖼️ 5. Load Scene Captions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32077c3a",
      "metadata": {
        "id": "32077c3a"
      },
      "outputs": [],
      "source": [
        "# Load captions from JSON\n",
        "import json\n",
        "captions_json = os.path.join(captions_path, f\"{os.path.splitext(video_filename)[0]}.json\")\n",
        "with open(captions_json, encoding='utf-8') as f:\n",
        "    scenes = json.load(f)\n",
        "scene_captions = [(scene, data[\"arabic\"]) for scene, data in scenes.items()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fea4337",
      "metadata": {
        "id": "9fea4337"
      },
      "source": [
        "# 🔡 6. Embed Captions and Transcript Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d20958ab",
      "metadata": {
        "id": "d20958ab"
      },
      "outputs": [],
      "source": [
        "# Encode using multilingual Sentence-BERT\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "caption_texts = [text for _, text in scene_captions]\n",
        "caption_embeddings = model.encode(caption_texts, convert_to_tensor=True)\n",
        "transcript_embeddings = model.encode(transcript_chunks, convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "501f8e8c",
      "metadata": {
        "id": "501f8e8c"
      },
      "source": [
        "# 🔗 7. Match Captions to Transcript Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80225615",
      "metadata": {
        "id": "80225615"
      },
      "outputs": [],
      "source": [
        "# Find best transcript match for each caption\n",
        "results = []\n",
        "similarities = util.cos_sim(caption_embeddings, transcript_embeddings)\n",
        "for i, (scene_id, caption_text) in enumerate(scene_captions):\n",
        "    sim_scores = similarities[i]\n",
        "    top_idx = sim_scores.argmax().item()\n",
        "    results.append({\n",
        "        \"scene_id\": scene_id,\n",
        "        \"caption\": caption_text,\n",
        "        \"best_transcript_chunk\": transcript_chunks[top_idx],\n",
        "        \"similarity_score\": float(sim_scores[top_idx])\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00c0e9ff",
      "metadata": {
        "id": "00c0e9ff"
      },
      "source": [
        "# 📥 8. Output Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "458b6474",
      "metadata": {
        "id": "458b6474"
      },
      "outputs": [],
      "source": [
        "# Display a few matches\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(results)\n",
        "df[['scene_id', 'caption', 'best_transcript_chunk', 'similarity_score']].head(10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}