{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raniamea/arabic-video-summarisation/blob/main/VideoProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa355c80",
      "metadata": {
        "id": "aa355c80"
      },
      "source": [
        "# 🎥 Arabic Video Multimodal Validator and Summarizer\n",
        "\n",
        "This Colab notebook lets you input the name of an Arabic video file and automatically performs:\n",
        "- Audio transcription (Arabic)\n",
        "- Scene/keyframe caption validation using Sentence-BERT and CLIP\n",
        "- (Optional) Abstractive summarization with mBART"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##♻️ 1. Setup Environment"
      ],
      "metadata": {
        "id": "_z2ibBr631mn"
      },
      "id": "_z2ibBr631mn"
    },
    {
      "cell_type": "code",
      "source": [
        "# === CORE BUILD TOOLS ===\n",
        "!pip install -U pip setuptools wheel --quiet\n",
        "# === TORCH (CUDA 11.8) ===\n",
        "!pip install torch==2.0.1 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118 --quiet\n",
        "# === NUMPY (compatible with OpenCV, Whisper, SceneDetect) ===\n",
        "!pip install numpy==1.24.4 --quiet\n",
        "# === OpenCV + SceneDetect ===\n",
        "!pip install opencv-python==4.7.0.72 opencv-contrib-python==4.7.0.72 scenedetect==0.6.6 --quiet\n",
        "# === Whisper for ASR ===\n",
        "!pip install git+https://github.com/openai/whisper.git --quiet\n",
        "# === Transformers for BLIP-2, MarianMT, etc. ===\n",
        "!pip install transformers==4.38.2 tokenizers>=0.14,<0.19 sentence-transformers sacremoses --quiet\n",
        "# === CAMeL Tools (for Arabic sentence tokenization etc.) ===\n",
        "!pip install git+https://github.com/CAMeL-Lab/camel_tools.git@master --quiet\n",
        "# === Audio & Image processing ===\n",
        "!pip install librosa==0.10.0.post2 soundfile Pillow --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m_XLlNaQJ7k",
        "outputId": "aa125d23-966a-4ac2-9dbc-b872f7477c28"
      },
      "id": "6m_XLlNaQJ7k",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorboard 2.18.0 requires numpy>=1.12.0, which is not installed.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "cufflinks 0.17.3 requires numpy>=1.9.2, which is not installed.\n",
            "pandas-gbq 0.29.2 requires numpy>=1.18.1, which is not installed.\n",
            "pytensor 2.31.7 requires numpy>=1.17.0, which is not installed.\n",
            "spanner-graph-notebook 1.1.6 requires numpy, which is not installed.\n",
            "spacy 3.8.7 requires numpy>=1.19.0; python_version >= \"3.9\", which is not installed.\n",
            "spacy 3.8.7 requires thinc<8.4.0,>=8.3.4, which is not installed.\n",
            "bqplot 0.12.45 requires numpy>=1.10.4, which is not installed.\n",
            "osqp 1.0.4 requires numpy>=1.7, which is not installed.\n",
            "bigframes 2.12.0 requires numpy>=1.24.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m148.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Building 'lit' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'lit'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [torchaudio]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "accelerate 1.9.0 requires numpy<3.0.0,>=1.17, which is not installed.\n",
            "peft 0.16.0 requires numpy>=1.17, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.10.6 requires jax>=0.5.1, which is not installed.\n",
            "spacy 3.8.7 requires thinc<8.4.0,>=8.3.4, which is not installed.\n",
            "optax 0.2.5 requires jax>=0.4.27, which is not installed.\n",
            "optax 0.2.5 requires jaxlib>=0.4.27, which is not installed.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, which is not installed.\n",
            "chex 0.1.90 requires jax>=0.4.27, which is not installed.\n",
            "chex 0.1.90 requires jaxlib>=0.4.27, which is not installed.\n",
            "dopamine-rl 4.1.2 requires jax>=0.1.72, which is not installed.\n",
            "dopamine-rl 4.1.2 requires jaxlib>=0.1.51, which is not installed.\n",
            "dopamine-rl 4.1.2 requires opencv-python>=3.4.8.29, which is not installed.\n",
            "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n",
            "orbax-checkpoint 0.11.19 requires jax>=0.5.0, which is not installed.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "scipy 1.16.0 requires numpy<2.6,>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [opencv-contrib-python]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires jax>=0.1.72, which is not installed.\n",
            "dopamine-rl 4.1.2 requires jaxlib>=0.1.51, which is not installed.\n",
            "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "/bin/bash: line 1: 0.19: No such file or directory\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.5/556.5 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m131.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for camel_tools (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for camel-kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Building 'docopt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'docopt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [camel_tools]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.10.6 requires jax>=0.5.1, which is not installed.\n",
            "spacy 3.8.7 requires thinc<8.4.0,>=8.3.4, which is not installed.\n",
            "optax 0.2.5 requires jax>=0.4.27, which is not installed.\n",
            "optax 0.2.5 requires jaxlib>=0.4.27, which is not installed.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, which is not installed.\n",
            "chex 0.1.90 requires jax>=0.4.27, which is not installed.\n",
            "chex 0.1.90 requires jaxlib>=0.4.27, which is not installed.\n",
            "dopamine-rl 4.1.2 requires jax>=0.1.72, which is not installed.\n",
            "dopamine-rl 4.1.2 requires jaxlib>=0.1.51, which is not installed.\n",
            "dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n",
            "orbax-checkpoint 0.11.19 requires jax>=0.5.0, which is not installed.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [librosa]\n",
            "\u001b[1A\u001b[2K"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Mount Google Drive & Define Folder Paths"
      ],
      "metadata": {
        "id": "e_VWwOEolSNk"
      },
      "id": "e_VWwOEolSNk"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import torch"
      ],
      "metadata": {
        "id": "7TimDWmjOC2b"
      },
      "id": "7TimDWmjOC2b",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Unmount first\n",
        "!fusermount -u /content/drive || echo \"Already unmounted\"\n",
        "\n",
        "# Delete the mount folder entirely\n",
        "!rm -rf /content/drive\n",
        "\n",
        "# Now mount again\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dTq6hem-Mwn",
        "outputId": "c4f15a56-ee2f-447b-f80c-1b98733c590d"
      },
      "id": "-dTq6hem-Mwn",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define base paths\n",
        "base_path = \"/content/drive/MyDrive/ArabicVideoSummariser\"\n",
        "videos_path = os.path.join(base_path, \"videos\")\n",
        "transcripts_path = os.path.join(base_path, \"transcripts\")\n",
        "captions_path = os.path.join(base_path, \"captions\")\n",
        "keyframes_path = os.path.join(base_path, \"keyframes\")\n",
        "os.makedirs(transcripts_path, exist_ok=True)\n",
        "os.makedirs(captions_path, exist_ok=True)\n",
        "os.makedirs(keyframes_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "MtOIIp158Tdz"
      },
      "id": "MtOIIp158Tdz",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ▶️ 3. Input Video Filename"
      ],
      "metadata": {
        "id": "kJfBHPBq3nqm"
      },
      "id": "kJfBHPBq3nqm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Video Filename\n",
        "video_filename = input(\"Enter the name of the video file (e.g., MyVideo.mp4): \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x1rnSV02iD4",
        "outputId": "9df760e6-d786-4a6b-ef1d-b149bdf05183"
      },
      "id": "-x1rnSV02iD4",
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the name of the video file (e.g., MyVideo.mp4): Calligraphy.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = os.path.join(videos_path, video_filename)\n",
        "assert os.path.exists(video_path), f\"Video file not found: {video_path}\"\n",
        "video_name = os.path.splitext(video_filename)[0]\n",
        "transcript_path = os.path.join(transcripts_path, f\"{video_name}_ar.txt\")\n",
        "translation_path = os.path.join(transcripts_path, f\"{video_name}_en.txt\")\n",
        "keyframe_dir = os.path.join(keyframes_path, video_name)\n",
        "os.makedirs(keyframe_dir, exist_ok=True)\n",
        "captions_json_path = os.path.join(captions_path, f\"{video_name}.json\")\n",
        "trascription_json_path = os.path.join(transcripts_path, f\"{video_name}.json\")\n"
      ],
      "metadata": {
        "id": "zsXhIfDs4kO5"
      },
      "id": "zsXhIfDs4kO5",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 🔊 4. Transcribe Arabic Audio using Whisper\n",
        "\n"
      ],
      "metadata": {
        "id": "e6PjCMXNBaHf"
      },
      "id": "e6PjCMXNBaHf"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "31fa5413",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31fa5413",
        "outputId": "70f13816-5f5b-4ade-87a9-570c777cc2a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numba/__init__.py:48: UserWarning: A NumPy version >=1.25.2 and <2.6.0 is required for this version of SciPy (detected version 1.24.4)\n",
            "  import scipy\n",
            "100%|█████████████████████████████████████| 2.88G/2.88G [01:06<00:00, 46.2MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:10.620]  في قلب القاهرة التاريخية حيث تتجسد الحضارة الإسلامية في كل زاوية\n",
            "[00:10.620 --> 00:16.380]  يروي الخط العربي حكاية أزلية عن الجمال والإبداع\n",
            "[00:16.380 --> 00:19.300]  إنه أكثر من مجرد خط\n",
            "[00:19.300 --> 00:23.180]  إنه فن، إنه هوية عربية\n",
            "[00:23.180 --> 00:26.760]  الخط العربي موجود من قبل الإسلام\n",
            "[00:26.760 --> 00:29.580]  يعني هو بقدم العرب\n",
            "[00:29.580 --> 00:32.180]  ولكن تطوره اختلف ما بعد الإسلام\n",
            "[00:32.180 --> 00:35.020]  فالخط العربي موجود ولكن لأنه هو\n",
            "[00:35.020 --> 00:40.380]  يعني ببساطة شديدة هو من عيلة الخطوط النباتية\n",
            "[00:40.380 --> 00:44.180]  ولكن الأمثلة اللي موجودة عندنا فعلا ما قبل الإسلام شيء\n",
            "[00:44.180 --> 00:46.560]  وما بعد الإسلام على طول شيء تاني خالص\n",
            "[00:46.560 --> 00:50.060]  ففي حاجة حصلت مع نزول الرسالة\n",
            "[00:50.060 --> 00:56.300]  وتتنوع الخطوط العربية بشكل كبير\n",
            "[00:56.300 --> 01:00.240]  حيث يروي كل خط عن عصر إصداره فيه\n",
            "[01:00.240 --> 01:02.480]  واستخدامات تميز بها\n",
            "[01:02.480 --> 01:07.320]  الأنواع الخط العربي طبعا هم كذا نوع كتير\n",
            "[01:07.320 --> 01:10.040]  مهماش بس نسخ والرقع زي ما بيعلمونا في المدرسة\n",
            "[01:10.040 --> 01:12.380]  وحتى النسخ والرقع بتقول المدرسة شيء\n",
            "[01:12.380 --> 01:18.820]  وخط النسخ والرقاع في تاريخ الخط العربي شيء تاني\n",
            "[01:18.820 --> 01:25.680]  هم النسخ والريحان والمحقق والثلث والرقاع والتوقيع\n",
            "[01:26.300 --> 01:30.420]  دول الستة الأساس اللي منهم طلع حاجات كتير جدا\n",
            "[01:30.420 --> 01:36.400]  ولأن الخط العربي ليس مجرد حروف\n",
            "[01:36.400 --> 01:38.880]  بل هو فن بحد ذاته\n",
            "[01:38.880 --> 01:43.260]  فإنه محكوم بقواعد دقيقة ومتناغمة\n",
            "[01:43.260 --> 01:47.640]  تجعل من تلك الخطوط لوحة فنية بذاتها\n",
            "[01:47.640 --> 01:50.620]  القواعد اللي بتحكم أي خط من الخطوط العربية\n",
            "[01:50.620 --> 01:52.700]  فيه قاعدة بتنطبق عليهم كلهم\n",
            "[01:52.700 --> 01:55.940]  وألوه هي أنه لازم يكون خط منسوب\n",
            "[01:56.300 --> 01:58.080]  منسوب بمعنى proportion\n",
            "[01:58.080 --> 02:04.680]  فهو المهم أنه الحرف للحرف بيبقى فيه نسبة معينة لازم تتبع\n",
            "[02:04.680 --> 02:06.680]  والكلمة للكلمة والسطر للسطر\n",
            "[02:06.680 --> 02:12.480]  لأنه بعد أبحاث كتير قوي لقوا أنه فيه golden ratio مثلا\n",
            "[02:12.480 --> 02:15.520]  golden ratio أو اللي هي النسبة الذهبية\n",
            "[02:15.520 --> 02:19.240]  دي حاجة ancient دي موجودة من أيام البني آدم نزل على الأرض\n",
            "[02:19.240 --> 02:22.520]  هي ال ratio اللي ربنا خلق بها الكون\n",
            "[02:22.520 --> 02:25.460]  فلما بتطبقيها في الفنون عموماً\n",
            "[02:25.460 --> 02:26.800]  عين البني آدم بتستريح\n",
            "[02:26.800 --> 02:29.560]  فالخطوط دي كلها لما بيطبق عليها\n",
            "[02:29.560 --> 02:32.240]  a ratio أو a proportion منسوب\n",
            "[02:32.240 --> 02:35.340]  بتلاقيها مستصاغة\n",
            "[02:35.340 --> 02:47.940]  وعلى الرغم من الدقة المتناهية والمعقدة التي يتطلبها نحت الخط العربي\n",
            "[02:47.940 --> 02:51.260]  لما يحتوي عليه من تفاصيل دقيقة\n",
            "[02:51.260 --> 02:55.260]  فإن الطلب على شراء اللوحات الرخمية لهذا الفن\n",
            "[02:55.460 --> 02:57.760]  شهد تراجعاً كبيراً\n",
            "[02:57.760 --> 03:02.260]  وأصبح مقتصراً على شواهد المقابر\n",
            "[03:02.260 --> 03:04.560]  النحت بيحتاج وقت طويل\n",
            "[03:04.560 --> 03:06.440]  عايز صبره كل الداني\n",
            "[03:06.440 --> 03:09.840]  وبعدين بالممارسة بيبقى الإنسان سريع شوية\n",
            "[03:09.840 --> 03:11.440]  خطوات النحت على الرخام\n",
            "[03:11.440 --> 03:13.440]  بتبتدي الأول بالخطات\n",
            "[03:13.440 --> 03:17.040]  يحدد المسافات ويكتب بالقلم البس\n",
            "[03:17.040 --> 03:19.040]  خط بالحبر الشيني عادي خالص\n",
            "[03:19.040 --> 03:21.060]  وبعدين أنا بتبتدي بالأزمين والمطراء\n",
            "[03:21.060 --> 03:23.460]  أنا حتلقيه اللي هو كتبه بالخط\n",
            "[03:23.460 --> 03:25.460]  وبعدين بتديهم بعد كده\n",
            "[03:25.460 --> 03:28.460]  باللون مثلاً اللي إحنا بنفضله\n",
            "[03:28.460 --> 03:32.200]  وبعدين بتتنضف ويبقى الطبيعة ترجع زي خط الخطات تاني\n",
            "[03:32.200 --> 03:34.200]  بس ما دون أبويا وما نحوط\n",
            "[03:34.200 --> 03:37.200]  فيه تراجع في اللوحات الرخام\n",
            "[03:37.200 --> 03:40.200]  لأن النظر أن العملية دلوقتي ما بقاش يعني\n",
            "[03:40.200 --> 03:43.440]  اللخام غالي والنحت غالي والسعوجر السماعي غالي\n",
            "[03:43.440 --> 03:45.240]  كل شيء بيغلط أمامنا\n",
            "[03:45.240 --> 03:46.740]  فالناس خلاص فيه تراجع\n",
            "[03:46.740 --> 03:48.240]  وبعدين فين اللافتات بتزبط\n",
            "[03:48.240 --> 03:51.880]  كلهم بيعملوا دلوقتي إنجليزة على لوحات المحلات وإضاءة وأنوار\n",
            "[03:51.880 --> 03:54.880]  إنما من الزمان كنا نعمل من لوحات المحلات\n",
            "[03:54.880 --> 03:58.880]  وجهات المحلات كنا بنعملها بالخط العربي ونكتبها لإسم المحل\n",
            "[03:58.880 --> 04:00.880]  الآن فيش كلام ده\n",
            "[04:00.880 --> 04:02.880]  ما تطور الزمن بقى\n",
            "[04:08.880 --> 04:10.880]  وبالدواية والقلم\n",
            "[04:10.880 --> 04:13.880]  ما زال طلاب مدرسة خليل أغاية\n",
            "[04:13.880 --> 04:15.880]  تعلمون فن الخط العربي على أسنو\n",
            "[04:15.880 --> 04:18.880]  فهي أول مدرسة أنشئت لتعليم هذا الفن\n",
            "[04:18.880 --> 04:20.880]  في منطقة الشرق الأوسط\n",
            "[04:20.880 --> 04:21.880]  في عهده\n",
            "[04:21.880 --> 04:23.880]  ورغم تدهور أوداع المدرسة\n",
            "[04:23.880 --> 04:26.880]  إلا إنها تشهد إقبال من الطلاب الراغبين لتعلم هذا الفن العريق\n",
            "[04:26.880 --> 04:28.880]  نعلم الطلاب جميع أنواع الخط العربي\n",
            "[04:28.880 --> 04:30.880]  الخمسة الأساسية\n",
            "[04:30.880 --> 04:34.880]  اللي هو خط السلس والنسخ والفرسي والركعة والجوانب\n",
            "[04:34.880 --> 04:37.880]  ثم بعد ذلك فيه التخصص\n",
            "[04:37.880 --> 04:39.880]  دبلوم تخصص وتزهيب\n",
            "[04:39.880 --> 04:41.880]  يوجد إجمال كبير\n",
            "[04:41.880 --> 04:43.880]  يوجد خط أساسي\n",
            "[04:43.880 --> 04:45.880]  يوجد خط أساسي\n",
            "[04:45.880 --> 04:47.880]  يوجد خط أساسي\n",
            "[04:47.880 --> 04:49.880]  يوجد خط أساسي\n",
            "[04:49.880 --> 04:50.880]  يوجد خط أساسي\n",
            "[04:50.880 --> 04:55.880]  يوجد إجمال كبير على الطلاب للحضور إلى المدرسة هنا\n",
            "[04:55.880 --> 04:59.880]  وخاصة الطلاب المبعوثين إلى جامعة الأزر الشريف\n",
            "[04:59.880 --> 05:04.880]  التحديات أن يجب أن يكون هناك كما عمل في ليبيا\n",
            "[05:04.880 --> 05:12.880]  مدرسة الخط العربي مختصة للذين يريدون أن يتعلموا الخط العربي ويعملوا به\n",
            "[05:12.880 --> 05:16.880]  أما غالبية العظمى للحضور هنا\n",
            "[05:16.880 --> 05:19.880]  فهم هاوون وليسوا محترقون\n",
            "[05:19.880 --> 05:25.880]  سنريد أن يكون كسم للمحترفين الذين سيستغلون بهذا الفن وكسم أخر للهواء\n",
            "[05:25.880 --> 05:33.880]  ورغم تدني أجور المدرسين في المدرسة التي لا تتجاوز خمسة جنيهات في الحصة\n",
            "[05:33.880 --> 05:35.880]  في أنهم ما زالوا متمسكين بتدريس فن الخط العربي\n",
            "[05:35.880 --> 05:41.880]  وذلك لإيمانهم بأهمية تعلمه كوسيلة للحفاظ على الهوية العربية\n",
            "[05:43.880 --> 05:45.880]  فهي تدريس الفن الخط العربي\n",
            "[05:45.880 --> 05:47.880]  فهي تدريس الفن الخط العربي\n",
            "[05:47.880 --> 05:55.200]  وفي هذا البيت العتيق يبدأ محمد شفعي في نحت لوحات الخط العربي\n",
            "[05:55.200 --> 05:59.600]  مستلهما من إرث عائلة العريق أصول فنونها\n",
            "[05:59.600 --> 06:06.020]  تخرج من مدرسة خليل أغى ونشأ في بيئة تعشق الخط العربي\n",
            "[06:06.020 --> 06:12.200]  منزل تعقبت عليه خمسة أجيال من أشهر خططين المصريين\n",
            "[06:12.200 --> 06:17.180]  بصماتهم واضحة وشاهدة عليهم في تاريخ الخط العربي\n",
            "[06:17.180 --> 06:24.020]  وما زالت هذه العائلة تحافظ على هذا الفن دي إيمانهم بأهميته\n",
            "[06:24.020 --> 06:29.580]  أنا محمد شفعي باحث وفيه فنان متخصص في فن الخط العربي\n",
            "[06:29.580 --> 06:34.000]  مهتم بفن الخط العربي بشكل خاص والفنون الإسلامية بشكل عام\n",
            "[06:34.000 --> 06:39.360]  ده راجع لسبب نشأتي في عائلة خالد سوفي زادة\n",
            "[06:39.360 --> 06:43.620]  هي عائلة متخصصة في الفنون الإسلامية وفن الخط العربي بشكل خاص\n",
            "[06:43.620 --> 06:46.260]  على مدار أكتر من 200 سنة\n",
            "[06:46.260 --> 06:47.000]  ده التاريخ\n",
            "[06:47.180 --> 06:50.380]  الموثق لتاريخ العائلة في العصر الحديث\n",
            "[06:50.380 --> 06:53.580]  وأنا بأعتبر الجيل الخامس من العائلة\n",
            "[06:53.580 --> 07:00.420]  اللي بشتغل إلى الآن وبمارس فن الخط العربي بشكل عملي\n",
            "[07:06.420 --> 07:10.180]  خليني أقولك أن فن الخط العربي مثل باقي الفنون\n",
            "[07:10.180 --> 07:14.060]  والمظاهر العمارة والحضارة في الأسور المختلفة\n",
            "[07:14.060 --> 07:16.980]  بيجي عليها عصور ازدهار وعصور\n",
            "[07:17.180 --> 07:22.380]  خفوط وعدم ازدهار فهنلاقي أنه فن الخط العربي بيجي\n",
            "[07:22.380 --> 07:27.100]  عليه أو أكتير كان فيه ازدهار حاليا في مصر بيشهد شيء من من\n",
            "[07:27.100 --> 07:33.800]  أشكال الازدهار في تعلم فن الخط العربي بين الأوساط المختلفة\n",
            "[07:33.800 --> 07:40.100]  الفنية وغير الفنية يعني في بعضهم بيبحث عن الجماليات داخل\n",
            "[07:40.100 --> 07:43.060]  فن الخط العربي والبعض بيبحث عن التراث والقدم وإزاي نستقي أعمالنا.\n",
            "[07:43.060 --> 07:44.020]  المواصلات التي تشتغلها في عام عام في المصر أو في مصر ومن أجل هذا لا يستطيع أن نتحدث عنها.\n",
            "[07:44.020 --> 07:51.240]  وإزاي نستقي أعمال تنتسب الحداسة من الأعمال القديمة التي تتناسب الأصالة\n",
            "[07:51.240 --> 07:56.120]  فهنلاقي فيه شيء من الرواك حالياً ولكن فيه أوساط مختلفة\n",
            "[07:56.120 --> 07:58.460]  ونتمنى طبعاً أن يبقى فيه اهتمام بشكل أكبر\n",
            "[07:58.460 --> 08:12.400]  وإيماناً بأهمية دوره قررت وزارة الثقافة تنظيم ملتقى الخط العربي\n",
            "[08:12.400 --> 08:17.180]  لتشجيع الشباب الموهبين على إنتاج لوحات بهذا الفن\n",
            "[08:17.180 --> 08:24.940]  وقد شارك عدد كبير في هذا الملتقى بلوحات أبرزت تطور أساليب وأشكال الخط العربي\n",
            "[08:24.940 --> 08:29.560]  كما شارك في الملتقى فنانون غير ناطقين بالعربية\n",
            "[08:29.560 --> 08:33.220]  مما يعكس الاهتمام العالمي بهذا الفن\n",
            "[08:33.220 --> 08:39.080]  يأتي ذلك إلى جانب جهود الوزارة في تسجيل الخط العربي\n",
            "[08:39.080 --> 08:42.180]  ضمن قوائم الصون العاجل للتراث الثقافي\n",
            "[08:42.400 --> 08:45.340]  غير المادي باليونسكو\n",
            "[08:45.340 --> 08:58.400]  سيظل الخط العربي جزءاً حياً من هويتنا العربية\n",
            "[08:58.920 --> 09:01.380]  محفور على جدران التاريخ\n",
            "[09:01.380 --> 09:06.160]  وستظل مسئولية الحفاظ عليه آمنة في أعناقنا\n",
            "[09:06.160 --> 09:09.880]  ولعل الاهتمام بالقائمين على هذا الفن\n",
            "[09:09.880 --> 09:11.880]  وتضمينه في المناهج التعليمية\n",
            "[09:12.400 --> 09:18.860]  هو الطريق الأمثل لضمان استمراره وتوارثه عبر الأجيال القادمة\n",
            "✅ Saved Arabic transcript to: /content/drive/MyDrive/ArabicVideoSummariser/transcripts/Calligraphy_ar.txt\n",
            "✅ Saved full Whisper output (AR) to: /content/drive/MyDrive/ArabicVideoSummariser/transcripts/Calligraphy.json\n",
            "[00:00.000 --> 00:02.000]  The Arab Line\n",
            "[00:04.000 --> 00:06.000]  In the heart of the historical Cairo,\n",
            "[00:06.000 --> 00:10.000]  where Islamic civilization is embodied in every angle,\n",
            "[00:10.000 --> 00:16.000]  the Arab Line tells an eternal story about beauty and creativity.\n",
            "[00:16.000 --> 00:19.000]  It is more than just a line.\n",
            "[00:19.000 --> 00:21.000]  It is art.\n",
            "[00:21.000 --> 00:23.000]  It is an Arab identity.\n",
            "[00:24.000 --> 00:27.000]  The Arab Line existed before Islam.\n",
            "[00:27.000 --> 00:30.000]  It was in the Arab era.\n",
            "[00:30.000 --> 00:32.000]  But it evolved and changed after Islam.\n",
            "[00:32.000 --> 00:34.000]  The Arab Line exists,\n",
            "[00:34.000 --> 00:40.000]  but it is simply a family of plant lines.\n",
            "[00:40.000 --> 00:47.000]  But the examples we have before and after Islam are different.\n",
            "[00:47.000 --> 00:50.000]  Something happened with the revelation of the message.\n",
            "[00:53.000 --> 00:56.000]  Arab lines are very diverse.\n",
            "[00:56.000 --> 00:57.000]  They are divided into three categories.\n",
            "[00:57.000 --> 01:00.000]  Each line tells about an era in which it was issued\n",
            "[01:00.000 --> 01:03.000]  and its unique uses.\n",
            "[01:04.000 --> 01:07.000]  There are many types of the Arab Line.\n",
            "[01:07.000 --> 01:09.000]  It is not just about copying and printing,\n",
            "[01:09.000 --> 01:10.000]  as they teach us in school.\n",
            "[01:10.000 --> 01:12.000]  Even copying and printing is a different thing.\n",
            "[01:12.000 --> 01:14.000]  And the line of copying and printing\n",
            "[01:14.000 --> 01:19.000]  in the history of the Arab Line is something else.\n",
            "[01:19.000 --> 01:22.000]  They are copying, printing,\n",
            "[01:22.000 --> 01:24.000]  verification, and printing,\n",
            "[01:24.000 --> 01:26.000]  printing, and signing.\n",
            "[01:26.000 --> 01:28.000]  These are the six main categories.\n",
            "[01:28.000 --> 01:30.000]  Many of them are very different.\n",
            "[01:33.000 --> 01:36.000]  The Arab Line is not just letters,\n",
            "[01:36.000 --> 01:39.000]  but it is an art in and of itself.\n",
            "[01:39.000 --> 01:43.000]  It is ruled by precise and harmonious lines.\n",
            "[01:43.000 --> 01:47.000]  These lines make an artistic painting.\n",
            "[01:48.000 --> 01:50.000]  The lines that rule any line in the Arab Line\n",
            "[01:50.000 --> 01:52.000]  have a rule that applies to all of them.\n",
            "[01:52.000 --> 01:55.000]  And that rule is that it must be a line that is applied.\n",
            "[01:56.000 --> 01:58.000]  It is applied in the meaning of proportion.\n",
            "[01:58.000 --> 02:02.000]  The important thing is that the letter to the letter\n",
            "[02:02.000 --> 02:04.000]  has a certain ratio that must be followed,\n",
            "[02:04.000 --> 02:07.000]  and the word to the word, and the line to the line.\n",
            "[02:07.000 --> 02:10.000]  After a lot of research,\n",
            "[02:10.000 --> 02:12.000]  they found that there is a golden ratio.\n",
            "[02:12.000 --> 02:16.000]  The golden ratio is something ancient.\n",
            "[02:16.000 --> 02:18.000]  It existed since the time of the human beings\n",
            "[02:18.000 --> 02:19.000]  when they descended on earth.\n",
            "[02:19.000 --> 02:22.000]  It is the ratio that God created the universe with.\n",
            "[02:22.000 --> 02:25.000]  When it is applied in art in general,\n",
            "[02:25.000 --> 02:27.000]  the eyes of the human being relax.\n",
            "[02:27.000 --> 02:29.000]  When all these lines are applied,\n",
            "[02:29.000 --> 02:32.000]  a ratio or a proportion is applied,\n",
            "[02:32.000 --> 02:35.000]  you find it consistent.\n",
            "[02:42.000 --> 02:45.000]  Despite the endless and complex accuracy\n",
            "[02:45.000 --> 02:48.000]  required by the Arab Line,\n",
            "[02:48.000 --> 02:51.000]  what it contains of precise details,\n",
            "[02:51.000 --> 02:54.000]  is that the demand to buy the digital paintings\n",
            "[02:54.000 --> 02:58.000]  for this art has witnessed a great decline.\n",
            "[02:58.000 --> 03:02.000]  And it has become limited to the details of the graves.\n",
            "[03:03.000 --> 03:05.000]  The sculpting takes a long time.\n",
            "[03:05.000 --> 03:07.000]  It takes patience and patience.\n",
            "[03:07.000 --> 03:08.000]  And then, with practice,\n",
            "[03:08.000 --> 03:10.000]  the human being becomes a little faster.\n",
            "[03:10.000 --> 03:12.000]  The steps of sculpting on the marble\n",
            "[03:12.000 --> 03:14.000]  start with the lines,\n",
            "[03:14.000 --> 03:16.000]  and define the distances,\n",
            "[03:16.000 --> 03:17.000]  and write with the pencil,\n",
            "[03:17.000 --> 03:19.000]  and the line with the pencil is normal.\n",
            "[03:19.000 --> 03:21.000]  And then I start with the lines and the lines,\n",
            "[03:21.000 --> 03:23.000]  and I will find what he wrote with the line.\n",
            "[03:24.000 --> 03:26.000]  And then I give them after that,\n",
            "[03:26.000 --> 03:28.000]  in the color that we prefer.\n",
            "[03:28.000 --> 03:30.000]  And then I clean it up,\n",
            "[03:30.000 --> 03:32.000]  and it will be normal to return to the same lines,\n",
            "[03:32.000 --> 03:40.560]  but without a\n",
            "[03:40.560 --> 03:42.000]  There is a decline in the paintings of the graves,\n",
            "[03:42.000 --> 03:43.000]  because the work is not expensive now.\n",
            "[03:43.000 --> 03:44.000]  The marble is expensive,\n",
            "[03:44.000 --> 03:45.000]  and the sky is expensive.\n",
            "[03:45.000 --> 03:46.000]  Everything is different.\n",
            "[03:46.000 --> 03:47.000]  People are in a decline.\n",
            "[03:47.000 --> 03:48.000]  And then where are the details?\n",
            "[03:48.000 --> 03:50.000]  They all make them now English\n",
            "[03:50.000 --> 03:51.000]  on the paintings of the shops,\n",
            "[03:51.000 --> 03:52.000]  and lighting, and lights.\n",
            "[03:52.000 --> 03:53.000]  When we used to start with the paintings of the shops,\n",
            "[03:53.000 --> 03:55.000]  we used to make them with the Arabic line,\n",
            "[03:55.000 --> 03:57.000]  and write down the name of the shop.\n",
            "[03:57.000 --> 03:59.000]  Now there is no such thing.\n",
            "[03:59.000 --> 04:01.000]  The time is evolving.\n",
            "[04:09.000 --> 04:11.000]  And with the tools and the pen,\n",
            "[04:11.000 --> 04:13.000]  students of Khalil Agha School\n",
            "[04:13.000 --> 04:15.000]  are still learning the art of the Arabic line\n",
            "[04:15.000 --> 04:16.000]  on their heads.\n",
            "[04:16.000 --> 04:17.000]  It is the first school\n",
            "[04:17.000 --> 04:19.000]  established to teach this art\n",
            "[04:19.000 --> 04:21.000]  in the Middle East region.\n",
            "[04:21.000 --> 04:23.000]  In the reign of King Fuad I,\n",
            "[04:23.000 --> 04:25.000]  the school was established in 1922\n",
            "[04:25.000 --> 04:27.000]  with the aim of preserving the Arabic identity.\n",
            "[04:27.000 --> 04:30.000]  Despite the decline of the school's facilities,\n",
            "[04:30.000 --> 04:32.000]  it still receives the acceptance of the students\n",
            "[04:32.000 --> 04:35.000]  who want to learn this ancient art.\n",
            "[04:35.000 --> 04:38.000]  We teach the students all kinds of the Arabic line,\n",
            "[04:38.000 --> 04:40.000]  the five main ones,\n",
            "[04:40.000 --> 04:42.000]  which are the line of the Trinity,\n",
            "[04:42.000 --> 04:43.000]  the Naseb,\n",
            "[04:43.000 --> 04:44.000]  the Persian,\n",
            "[04:44.000 --> 04:45.000]  the Ruk'ah,\n",
            "[04:45.000 --> 04:46.000]  and the Juhani.\n",
            "[04:46.000 --> 04:48.000]  Then there is the specialization,\n",
            "[04:48.000 --> 04:50.000]  the diploma of specialization and graduation.\n",
            "[04:50.000 --> 04:52.000]  There is a great majority of students\n",
            "[04:52.000 --> 04:55.000]  who want to attend the school here,\n",
            "[04:55.000 --> 04:57.000]  especially the students\n",
            "[04:57.000 --> 05:00.000]  who are sent to the Al-Azhar Al-Sharif University.\n",
            "[05:00.000 --> 05:03.000]  The challenges are that there must be,\n",
            "[05:03.000 --> 05:05.000]  as was done in Libya,\n",
            "[05:05.000 --> 05:07.000]  a school of the Arabic line\n",
            "[05:07.000 --> 05:11.000]  dedicated to those who want to learn the Arabic line\n",
            "[05:11.000 --> 05:13.000]  and work with it.\n",
            "[05:13.000 --> 05:16.000]  As for the great majority of those who come here,\n",
            "[05:16.000 --> 05:19.000]  they are nomads and not experts.\n",
            "[05:19.000 --> 05:21.000]  We want to be a part of the experts\n",
            "[05:21.000 --> 05:24.000]  who will work with this art\n",
            "[05:24.000 --> 05:26.000]  and another part of the hobby.\n",
            "[05:26.000 --> 05:29.000]  Despite the cost of teachers' salaries at the school,\n",
            "[05:29.000 --> 05:32.000]  which is not exceeding 5 pounds per class,\n",
            "[05:32.000 --> 05:36.000]  they are still attached to teaching the Arabic line art,\n",
            "[05:36.000 --> 05:39.000]  because they believe that learning is important\n",
            "[05:39.000 --> 05:42.000]  as a means of preserving the Arabic identity.\n",
            "[05:49.000 --> 05:51.000]  In this ancient house,\n",
            "[05:51.000 --> 05:55.000]  Mohamed Shafi'i is creating the Arabic line\n",
            "[05:55.000 --> 05:57.000]  with the help of his family.\n",
            "[05:57.000 --> 05:59.000]  He is inspired by the family's heritage\n",
            "[05:59.000 --> 06:01.000]  and the ancient principles of their art.\n",
            "[06:01.000 --> 06:03.000]  He graduated from Khalil Agha School\n",
            "[06:03.000 --> 06:06.000]  and was born in an environment that admires the Arabic line.\n",
            "[06:06.000 --> 06:09.000]  It is a house that has been preserved\n",
            "[06:09.000 --> 06:12.000]  by five generations of the most famous Egyptian writers.\n",
            "[06:12.000 --> 06:15.000]  Their drawings are clear and they are witnessed\n",
            "[06:15.000 --> 06:17.000]  in the history of the Arabic line.\n",
            "[06:17.000 --> 06:19.000]  This family still preserves this tradition.\n",
            "[06:19.000 --> 06:24.000]  This is their belief in the importance of this art.\n",
            "[06:24.000 --> 06:26.000]  I am Mohamed Shafi'i,\n",
            "[06:26.000 --> 06:29.000]  a researcher and an artist specializing in the Arabic line art.\n",
            "[06:29.000 --> 06:32.000]  I am interested in the Arabic line art in particular\n",
            "[06:32.000 --> 06:34.000]  and Islamic arts in general.\n",
            "[06:34.000 --> 06:39.000]  This is because I was born in the family of Khaled Soufi Zada.\n",
            "[06:39.000 --> 06:42.000]  It is a family specialized in Islamic arts\n",
            "[06:42.000 --> 06:44.000]  and the Arabic line art in particular\n",
            "[06:44.000 --> 06:46.000]  for more than 200 years.\n",
            "[06:46.000 --> 06:47.000]  This is the history of the family.\n",
            "[06:47.000 --> 06:50.000]  I am a member of the family's fifth generation\n",
            "[06:50.000 --> 06:53.000]  and I have been working and practicing the Arabic line art\n",
            "[06:53.000 --> 06:55.000]  in a practical way.\n",
            "[06:55.000 --> 06:58.000]  The Arabic line art is like other arts,\n",
            "[06:58.000 --> 07:01.000]  the architectural and cultural manifestations\n",
            "[07:01.000 --> 07:03.000]  in different eras.\n",
            "[07:03.000 --> 07:06.000]  It has the era of prosperity and the era of art.\n",
            "[07:06.000 --> 07:08.000]  The Arabic line art is a work of art\n",
            "[07:08.000 --> 07:10.000]  that is not only a work of art\n",
            "[07:10.000 --> 07:12.000]  but also a work of art that is a work of art.\n",
            "[07:12.000 --> 07:14.000]  It is a work of art that is a work of art\n",
            "[07:14.000 --> 07:16.000]  and a work of art that is a work of art.\n",
            "[07:17.000 --> 07:19.000]  It is a work of art that is a work of art\n",
            "[07:19.000 --> 07:21.000]  and it has the era of prosperity and the era of art.\n",
            "[07:21.000 --> 07:23.000]  We will find that the Arabic line art\n",
            "[07:23.000 --> 07:24.000]  has a lot of prosperity\n",
            "[07:24.000 --> 07:26.000]  in Egypt right now.\n",
            "[07:26.000 --> 07:30.000]  It bears the form of prosperity.\n",
            "[07:30.000 --> 07:32.000]  There is a learning of the Arabic line art\n",
            "[07:32.000 --> 07:34.000]  between the different media,\n",
            "[07:34.000 --> 07:37.000]  the artistic and the non-artistic.\n",
            "[07:37.000 --> 07:40.000]  Some people are looking for the beauties\n",
            "[07:40.000 --> 07:42.000]  within the Arabic line art art\n",
            "[07:42.000 --> 07:44.000]  and some are looking for the heritage,\n",
            "[07:44.000 --> 07:45.000]  the ancient,\n",
            "[07:45.000 --> 07:47.000]  and how to use it\n",
            "[07:47.000 --> 07:49.000]  to create works that are modernized\n",
            "[07:49.000 --> 07:50.000]  from the ancient works\n",
            "[07:50.000 --> 07:52.000]  that are distinguished by the originality.\n",
            "[07:52.000 --> 07:54.000]  We will find some of the prosperity\n",
            "[07:54.000 --> 07:56.000]  but there are different mediums\n",
            "[07:56.000 --> 07:57.000]  and we hope that there will be\n",
            "[07:57.000 --> 07:59.000]  more interest.\n",
            "[08:06.000 --> 08:08.000]  Believing in the importance of its role,\n",
            "[08:08.000 --> 08:11.000]  the Ministry of Culture decided to organize\n",
            "[08:11.000 --> 08:13.000]  the Arabic Line Art Collective\n",
            "[08:13.000 --> 08:15.000]  to encourage talented youth\n",
            "[08:15.000 --> 08:17.000]  to produce paintings with this art\n",
            "[08:17.000 --> 08:19.000]  and a large number of people\n",
            "[08:19.000 --> 08:21.000]  participated in this project\n",
            "[08:21.000 --> 08:23.000]  with paintings that showed the development\n",
            "[08:23.000 --> 08:25.000]  of Arabic line patterns and shapes.\n",
            "[08:25.000 --> 08:27.000]  As artists participating in the project,\n",
            "[08:27.000 --> 08:29.000]  non-Arabic speakers\n",
            "[08:29.000 --> 08:31.000]  reflect the global interest\n",
            "[08:31.000 --> 08:33.000]  in this art.\n",
            "[08:33.000 --> 08:36.000]  This comes to the side of the Ministry's efforts\n",
            "[08:36.000 --> 08:39.000]  in recording the Arabic line\n",
            "[08:39.000 --> 08:42.000]  within the urgent design of the non-material\n",
            "[08:42.000 --> 08:45.000]  cultural heritage in UNESCO.\n",
            "[08:47.000 --> 08:49.000]  The Arabian Line Art Collective\n",
            "[08:49.000 --> 08:51.000]  is a part of our Arab identity\n",
            "[08:51.000 --> 08:53.000]  and it is a part of our history.\n",
            "[08:53.000 --> 08:55.000]  Our responsibility is to preserve it\n",
            "[08:55.000 --> 08:57.000]  and to keep it safe in our hearts.\n",
            "[08:57.000 --> 08:59.000]  Perhaps the interest of those who are\n",
            "[08:59.000 --> 09:00.000]  interested in this art\n",
            "[09:00.000 --> 09:04.100]  and its\n",
            "[09:04.100 --> 09:06.000]  guarantee in educational methods\n",
            "[09:06.000 --> 09:09.000]  is the best way to guarantee its continuity\n",
            "[09:09.000 --> 09:11.000]  and heritage.\n",
            "[09:11.000 --> 09:13.000]  We hope that the Arab Line Art Collective\n",
            "[09:13.000 --> 09:15.000]  will continue to provide\n",
            "[09:15.000 --> 09:16.400]  a\n",
            "[09:16.400 --> 09:19.440]  lasting andいい\n",
            "[09:19.440 --> 09:21.820]  inspiration forberry\n",
            "[09:21.820 --> 09:28.400]  to these generations.\n",
            "✅ Saved English translation to: /content/drive/MyDrive/ArabicVideoSummariser/transcripts/Calligraphy_en.txt\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "import json\n",
        "\n",
        "# Load Whisper model\n",
        "model = whisper.load_model(\"large\", device=\"cuda\")\n",
        "\n",
        "# transcribe (Arabic)\n",
        "result = model.transcribe(video_path, language=\"ar\", task=\"transcribe\", verbose=True)\n",
        "\n",
        "with open(transcript_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(result['text'])\n",
        "print(f\"✅ Saved Arabic transcript to: {transcript_path}\")\n",
        "\n",
        "with open(transcript_path.replace(\".txt\", \"_with_timecodes.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    for segment in result[\"segments\"]:\n",
        "        start = segment[\"start\"]\n",
        "        end = segment[\"end\"]\n",
        "        text = segment[\"text\"]\n",
        "        f.write(f\"[{start:.2f} - {end:.2f}] {text}\\n\")\n",
        "\n",
        "# ✅ Save full result as JSON (NEW)\n",
        "with open(trascription_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(result, f, ensure_ascii=False, indent=2)\n",
        "print(f\"✅ Saved full Whisper output (AR) to: {trascription_json_path}\")\n",
        "\n",
        "# Translate (Arabic → English)\n",
        "result_en = model.transcribe(video_path, language=\"ar\", task=\"translate\", verbose=True)\n",
        "with open(translation_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(result_en[\"text\"])\n",
        "print(f\"✅ Saved English translation to: {translation_path}\")\n",
        "\n",
        "# Save timecoded translation\n",
        "with open(translation_path.replace(\".txt\", \"_with_timecodes.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    for segment in result_en[\"segments\"]:\n",
        "        start = segment[\"start\"]\n",
        "        end = segment[\"end\"]\n",
        "        text = segment[\"text\"]\n",
        "        f.write(f\"[{start:.2f} - {end:.2f}] {text}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🖼️ 5. KeyFrame Detection & Captioning"
      ],
      "metadata": {
        "id": "o1HpAGrQQ7ro"
      },
      "id": "o1HpAGrQQ7ro"
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import json\n",
        "from PIL import Image\n",
        "from scenedetect import open_video, SceneManager\n",
        "#from scenedetect import VideoManager, SceneManager\n",
        "from scenedetect.detectors import ContentDetector\n",
        "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "\n",
        "# ============ SETUP ============\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# BLIP-2 model\n",
        "caption_processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-opt-2.7b\",use_fast=False)\n",
        "caption_model = Blip2ForConditionalGeneration.from_pretrained(\n",
        "    \"Salesforce/blip2-opt-2.7b\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
        ").to(device)\n",
        "\n",
        "# Translation model (EN → AR)\n",
        "translator_tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\")\n",
        "translator_model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\").to(device)\n",
        "\n",
        "\n",
        "\n",
        "captions = {}\n",
        "\n",
        "scene_manager = SceneManager()\n",
        "scene_manager.add_detector(ContentDetector(threshold=30.0))\n",
        "video = open_video(video_path)\n",
        "scene_manager.detect_scenes(video)\n",
        "scene_list = scene_manager.get_scene_list()\n",
        "\n",
        "# --- Extract frames ---\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "for i, (start, _) in enumerate(scene_list):\n",
        "  frame_num = int(start.get_seconds() * fps)\n",
        "  cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    continue\n",
        "\n",
        "  frame_name = f\"scene_{i:03}.jpg\"\n",
        "  frame_path = os.path.join(keyframe_dir, frame_name)\n",
        "  cv2.imwrite(frame_path, frame)\n",
        "\n",
        "  # Convert to PIL\n",
        "  image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  # --- Captioning with BLIP-2 ---\n",
        "  inputs = caption_processor(images=image, return_tensors=\"pt\").to(device, torch.float16 if device == \"cuda\" else torch.float32)\n",
        "  generated_ids = caption_model.generate(**inputs, max_new_tokens=50)\n",
        "  english_caption = caption_processor.decode(generated_ids[0], skip_special_tokens=True).strip()\n",
        "\n",
        "  # --- Translate to Arabic ---\n",
        "  translation_inputs = translator_tokenizer(english_caption, return_tensors=\"pt\", padding=True).to(device)\n",
        "  translated = translator_model.generate(**translation_inputs)\n",
        "  arabic_caption = translator_tokenizer.decode(translated[0], skip_special_tokens=True).strip()\n",
        "\n",
        "  # --- Save result with scene start time ---\n",
        "  captions[frame_name] = {\n",
        "    \"scene_time\": round(start.get_seconds(), 2),  # Time in seconds, rounded for readability\n",
        "    \"english\": english_caption,\n",
        "    \"arabic\": arabic_caption\n",
        "    }\n",
        "\n",
        "  print(f\"✓ {frame_name} @ {start.get_seconds():.2f}s | EN: {english_caption} | AR: {arabic_caption}\")\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# Save JSON\n",
        "with open(captions_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "  json.dump(captions, f, ensure_ascii=False, indent=2)\n",
        "print(f\"✅ Captions saved to: {json_path}\")"
      ],
      "metadata": {
        "id": "hBfFY4xeKa5n"
      },
      "execution_count": null,
      "outputs": [],
      "id": "hBfFY4xeKa5n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧹 6. Clean the Script"
      ],
      "metadata": {
        "id": "ThznxocQv7uh"
      },
      "id": "ThznxocQv7uh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1. Clean the Transcript"
      ],
      "metadata": {
        "id": "4EykBV4P8EBl"
      },
      "id": "4EykBV4P8EBl"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from camel_tools.tokenizers.word import simple_word_tokenize\n",
        "from camel_tools.utils.charmap import CharMapper\n",
        "from camel_tools.disambig.mle import MLEDisambiguator\n",
        "\n",
        "# ==== Setup ====\n",
        "normalizer = CharMapper.builtin_mapper('arclean')\n",
        "\n",
        "disambig = MLEDisambiguator.pretrained()\n",
        "\n",
        "# ==== Function: Clean, Segment, POS tag ====\n",
        "def arabic_segment_and_analyze(text):\n",
        "    # Normalize Arabic text (removes Tatweel, unifies alef/ya, strips diacritics)\n",
        "    normalized_text = normalizer.map_string(text)\n",
        "\n",
        "    # Insert sentence breaks based on conjunctions and commas\n",
        "    segmented = re.sub(r'(?<=\\S)\\s+(?=(و|ثم|لكن|ف|بعد|إلا أن|غير أن)\\s)', r'. ', normalized_text)\n",
        "    segmented = re.sub(r'،|\\.\\s*', '.\\n', segmented)\n",
        "    sentences = [s.strip() for s in segmented.split('\\n') if s.strip()]\n",
        "\n",
        "    # POS tagging\n",
        "    results = []\n",
        "    for sent in sentences:\n",
        "        tokens = simple_word_tokenize(sent)\n",
        "        disambig_results = disambig.disambiguate(tokens)\n",
        "        tagged = [(tok, d.analyses[0].analysis['pos']) for tok, d in zip(tokens, disambig_results)]\n",
        "        results.append({\n",
        "            \"sentence\": sent,\n",
        "            \"tokens_with_pos\": tagged\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# ==== File Paths ====\n",
        "output_txt = os.path.join(transcripts_path, f\"{video_name}_segmented_ar.txt\")\n",
        "\n",
        "# ==== Run segmentation ====\n",
        "with open(transcript_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "segmented = arabic_segment_and_analyze(raw_text)\n",
        "\n",
        "# ==== Save output ====\n",
        "with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "    for item in segmented:\n",
        "        f.write(item['sentence'] + '\\n')\n",
        "\n",
        "print(f\"✅ Segmented transcript saved to: {output_txt}\")\n"
      ],
      "metadata": {
        "id": "m-lXmHon_n5G"
      },
      "id": "m-lXmHon_n5G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2. Clean the captions"
      ],
      "metadata": {
        "id": "AGZ5Ydcc8MQa"
      },
      "id": "AGZ5Ydcc8MQa"
    },
    {
      "cell_type": "markdown",
      "id": "eef4a65b",
      "metadata": {
        "id": "eef4a65b"
      },
      "source": [
        "## 🧠 7. Process Transcript into Overlapping Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa7a3d4",
      "metadata": {
        "id": "1aa7a3d4"
      },
      "outputs": [],
      "source": [
        "!pip install transformers --quiet\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# === Load tokenizer ===\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabertv2\")\n",
        "\n",
        "# === Load transcript text ===\n",
        "with open(transcript_txt, encoding=\"utf-8\") as f:\n",
        "    full_transcript = f.read()\n",
        "\n",
        "# === Tokenize in small overlapping windows ===\n",
        "tokens = tokenizer.tokenize(full_transcript)\n",
        "\n",
        "# Define chunking parameters\n",
        "chunk_size = 128\n",
        "step = 64\n",
        "\n",
        "# Generate safe overlapping chunks (as token strings)\n",
        "token_chunks = [tokens[i:i+chunk_size] for i in range(0, len(tokens) - chunk_size + 1, step)]\n",
        "\n",
        "# Convert token chunks back to readable strings\n",
        "text_chunks = [tokenizer.convert_tokens_to_string(chunk) for chunk in token_chunks]\n",
        "\n",
        "# Prepare model-ready input (≤512 tokens, padded)\n",
        "tokenized_chunks = [\n",
        "    tokenizer(chunk_text, return_tensors=\"pt\", truncation=True, max_length=512, padding=\"max_length\")\n",
        "    for chunk_text in text_chunks\n",
        "]\n",
        "\n",
        "# Preview\n",
        "for i, chunk in enumerate(text_chunks[:3]):\n",
        "    print(f\"\\n--- Chunk {i+1} ---\\n{chunk}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fd49d45",
      "metadata": {
        "id": "8fd49d45"
      },
      "source": [
        "## 🖼️ 8. Load Scene Captions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32077c3a",
      "metadata": {
        "id": "32077c3a"
      },
      "outputs": [],
      "source": [
        "# Load captions from JSON\n",
        "import json\n",
        "captions_json = os.path.join(captions_path, f\"{os.path.splitext(video_filename)[0]}.json\")\n",
        "with open(captions_json, encoding='utf-8') as f:\n",
        "    scenes = json.load(f)\n",
        "scene_captions = [(scene, data[\"arabic\"]) for scene, data in scenes.items()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fea4337",
      "metadata": {
        "id": "9fea4337"
      },
      "source": [
        "## 🔡 9. Embed Captions and Transcript Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d20958ab",
      "metadata": {
        "id": "d20958ab"
      },
      "outputs": [],
      "source": [
        "# Encode using multilingual Sentence-BERT\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "caption_texts = [text for _, text in scene_captions]\n",
        "caption_embeddings = model.encode(caption_texts, convert_to_tensor=True)\n",
        "transcript_embeddings = model.encode(transcript_chunks, convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "501f8e8c",
      "metadata": {
        "id": "501f8e8c"
      },
      "source": [
        "## 🔗 10. Match Captions to Transcript Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80225615",
      "metadata": {
        "id": "80225615"
      },
      "outputs": [],
      "source": [
        "# Find best transcript match for each caption\n",
        "results = []\n",
        "similarities = util.cos_sim(caption_embeddings, transcript_embeddings)\n",
        "for i, (scene_id, caption_text) in enumerate(scene_captions):\n",
        "    sim_scores = similarities[i]\n",
        "    top_idx = sim_scores.argmax().item()\n",
        "    results.append({\n",
        "        \"scene_id\": scene_id,\n",
        "        \"caption\": caption_text,\n",
        "        \"best_transcript_chunk\": transcript_chunks[top_idx],\n",
        "        \"similarity_score\": float(sim_scores[top_idx])\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00c0e9ff",
      "metadata": {
        "id": "00c0e9ff"
      },
      "source": [
        "## 📥 11. Output Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "458b6474",
      "metadata": {
        "id": "458b6474"
      },
      "outputs": [],
      "source": [
        "# Display a few matches\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(results)\n",
        "df[['scene_id', 'caption', 'best_transcript_chunk', 'similarity_score']].head(10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_z2ibBr631mn",
        "e_VWwOEolSNk",
        "kJfBHPBq3nqm",
        "ThznxocQv7uh",
        "4EykBV4P8EBl",
        "eef4a65b",
        "8fd49d45",
        "9fea4337",
        "501f8e8c",
        "00c0e9ff"
      ],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}