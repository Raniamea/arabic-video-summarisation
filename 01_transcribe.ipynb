{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMPRc2FaXWWJ56nERVdimJa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raniamea/arabic-video-summarisation/blob/main/01_transcribe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚨 Reset Colab Python Kernel Automatically After Downgrading NumPy\n",
        "!pip install numpy==1.23.5 --force-reinstall --no-cache-dir\n",
        "import os; os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoON3DGi7M8M",
        "outputId": "8c735ca0-15c5-4e5e-a65f-a8499c6b9f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m275.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 2.12.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.3 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.0.1+cu118 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.3 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "contourpy 1.3.3 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "geopandas 1.1.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.90 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "scipy 1.16.1 requires numpy<2.6,>=1.25.2, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Whisper and Torch\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q torch==2.0.1 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "!apt-get install ffmpeg\n",
        "!pip install -q pydub"
      ],
      "metadata": {
        "id": "DIUtvDSNHQxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f47473-c691-4f3a-cc2e-a7870ac16182"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qOtSkLoSHLpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960cdbc6-5645-4916-897c-c817d3247b8d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Path to your params.json on Google Drive\n",
        "param_path = \"/content/drive/MyDrive/ArabicVideoSummariser/params.json\"\n",
        "\n",
        "# Load it\n",
        "with open(param_path, \"r\") as f:\n",
        "    params = json.load(f)\n",
        "\n",
        "# Get the filename\n",
        "video_filename = params.get(\"video_file\")\n",
        "print(\"🎥 Transcribing video file:\", video_filename)\n",
        "\n",
        "from pydub import AudioSegment\n",
        "import math\n",
        "\n",
        "# Define base paths\n",
        "base_path = \"/content/drive/MyDrive/ArabicVideoSummariser\"\n",
        "videos_path = os.path.join(base_path, \"videos\")\n",
        "transcripts_path = os.path.join(base_path, \"transcripts\")\n",
        "\n",
        "video_path = os.path.join(videos_path, video_filename)\n",
        "video_name = os.path.splitext(video_filename)[0]\n",
        "transcript_path = os.path.join(transcripts_path, f\"{video_name}_ar.txt\")\n",
        "translation_path = os.path.join(transcripts_path, f\"{video_name}_en.txt\")\n",
        "trascription_json_path = os.path.join(transcripts_path, f\"{video_name}_ar.json\")\n",
        "translation_json_path = os.path.join(transcripts_path, f\"{video_name}_en.json\")\n",
        "\n",
        "# Convert video to audio\n",
        "audio_path = os.path.join(videos_path, f\"{video_name}.wav\")\n",
        "!ffmpeg -y -i \"{video_path}\" -ar 16000 -ac 1 \"{audio_path}\"  # Resample to 16kHz mono\n",
        "\n",
        "# Load audio using pydub\n",
        "audio = AudioSegment.from_wav(audio_path)\n",
        "chunk_length_ms = 30 * 1000  # 30 seconds\n",
        "total_chunks = math.ceil(len(audio) / chunk_length_ms)\n",
        "\n",
        "print(f\"🔊 Audio duration: {len(audio) / 1000:.1f}s, Chunks: {total_chunks}\")\n"
      ],
      "metadata": {
        "id": "MaUj-uJnyqz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a87fae-5436-49c1-b2ee-c904ead4e36e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎥 Transcribing video file: PaperMaking.mp4\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/drive/MyDrive/ArabicVideoSummariser/videos/PaperMaking.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    creation_time   : 2024-01-30T20:36:16.000000Z\n",
            "  Duration: 00:05:54.73, start: 0.000000, bitrate: 1084 kb/s\n",
            "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1280x720 [SAR 1:1 DAR 16:9], 952 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2024-01-30T20:36:16.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 01/30/2024.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2024-01-30T20:36:16.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 01/30/2024.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to '/content/drive/MyDrive/ArabicVideoSummariser/videos/PaperMaking.wav':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2024-01-30T20:36:16.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 01/30/2024.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 pcm_s16le\n",
            "size=   11085kB time=00:05:54.73 bitrate= 256.0kbits/s speed= 522x    \n",
            "video:0kB audio:11085kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000687%\n",
            "🔊 Audio duration: 354.7s, Chunks: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "31fa5413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f58a068-6701-4207-9214-37ffe1ed0114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numba/__init__.py:48: UserWarning: A NumPy version >=1.25.2 and <2.6.0 is required for this version of SciPy (detected version 1.23.5)\n",
            "  import scipy\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Transcribing chunk 1/12 (0.0s - 30.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:02<00:00, 1226.13frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Transcribing chunk 2/12 (30.0s - 60.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:06<00:00, 448.61frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Transcribing chunk 3/12 (60.0s - 90.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:05<00:00, 556.52frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Transcribing chunk 4/12 (90.0s - 120.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:05<00:00, 592.67frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Transcribing chunk 5/12 (120.0s - 150.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:05<00:00, 501.32frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Transcribing chunk 6/12 (150.0s - 180.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:01<00:00, 1654.82frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Transcribing chunk 7/12 (180.0s - 210.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:02<00:00, 1247.34frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Transcribing chunk 8/12 (210.0s - 240.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:04<00:00, 721.09frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Transcribing chunk 9/12 (240.0s - 270.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:04<00:00, 626.66frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Transcribing chunk 10/12 (270.0s - 300.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:02<00:00, 1226.01frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Transcribing chunk 11/12 (300.0s - 330.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:07<00:00, 421.04frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Transcribing chunk 12/12 (330.0s - 354.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2473/2473 [00:03<00:00, 623.59frames/s]\n"
          ]
        }
      ],
      "source": [
        "import torch, whisper, json, gc\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "model = whisper.load_model(\"large\", device=\"cuda\", in_memory=True)\n",
        "\n",
        "\n",
        "results = []\n",
        "for i in range(total_chunks):\n",
        "    start_ms = i * chunk_length_ms\n",
        "    end_ms = min((i + 1) * chunk_length_ms, len(audio))\n",
        "    chunk = audio[start_ms:end_ms]\n",
        "    chunk_file = f\"/content/chunk_{i}.wav\"\n",
        "    chunk.export(chunk_file, format=\"wav\")\n",
        "\n",
        "    print(f\"⏱️ Transcribing chunk {i+1}/{total_chunks} ({start_ms/1000:.1f}s - {end_ms/1000:.1f}s)\")\n",
        "    result = model.transcribe(chunk_file, language=\"ar\", task=\"transcribe\", verbose=False, fp16=False)\n",
        "\n",
        "    for segment in result['segments']:\n",
        "        segment[\"start\"] += start_ms / 1000\n",
        "        segment[\"end\"] += start_ms / 1000\n",
        "        results.append(segment)\n",
        "\n",
        "# Save text transcript\n",
        "with open(transcript_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\" \".join([seg[\"text\"] for seg in results]))\n",
        "\n",
        "# Save time-coded transcript\n",
        "with open(transcript_path.replace(\".txt\", \"_with_timecodes.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    for seg in results:\n",
        "        f.write(f\"[{seg['start']:.2f} - {seg['end']:.2f}] {seg['text']}\\n\")\n",
        "\n",
        "# Save JSON\n",
        "with open(trascription_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump({\"segments\": results}, f, ensure_ascii=False, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "qeXd-Xmm16To"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}